# 机器学习笔记

## k-NN算法

* 创建数据集

  ```python
  def createDataSet():
      #四组二维特征
      group = np.array([[1,101],[5,89],[108,5],[115,8]])
      #四组特征的标签
      labels = ['爱情片','爱情片','动作片','动作片']
      return group, labels
  ```

  * 伪代码

    ```python
    def createDataSet():
        新建numpy二维数组来存储各个点在各个特征上的取值
        新建数组来存储对应点的标签取值
        返回新建的numpy二维数组和数组
    ```

* k-NN算法分类器

  ```python
  def classify0(inX, dataSet, labels, k):
      #numpy函数shape[0]返回dataSet的行数
      dataSetSize = dataSet.shape[0]
      #在列向量方向上重复inX共1次(横向)，行向量方向上重复inX共dataSetSize次(纵向)
      diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet
      #二维特征相减后平方
      sqDiffMat = diffMat**2
      #sum()所有元素相加，sum(0)列相加，sum(1)行相加
      sqDistances = sqDiffMat.sum(axis=1)
      #开方，计算出距离
      distances = sqDistances**0.5
      #返回distances中元素从小到大排序后的索引值
      sortedDistIndices = distances.argsort()
      #定一个记录类别次数的字典
      classCount = {}
      for i in range(k):
          #取出前k个元素的类别
          voteIlabel = labels[sortedDistIndices[i]]
          #dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。
          #计算类别次数
          classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
      #python3中用items()替换python2中的iteritems()
      #key=operator.itemgetter(1)根据字典的值进行排序
      #key=operator.itemgetter(0)根据字典的键进行排序
      #reverse降序排序字典
      sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)
      #返回次数最多的类别,即所要分类的类别
      return sortedClassCount[0][0]
  ```

  * 伪代码

    ```python
    def classify0(inX, dataSet, labels, k):
        对dataSet调用shape[0]方法获得矩阵行数
        根据inX(新加入的点的各个特征的取值)将其张成一个和dataSet一样大的矩阵
        将inX张成的矩阵和dataSet相减获得diffMat
        将diffMat平方获得sqDiffMat
        对sqDiffMat调用sum(axis=1)方法获得每行元素相加后的矩阵sqDistances
        将sqDistances开方获得距离矩阵distances
        对distances调用argsort方法返回其中元素按小到大排序后的索引值,存储于sortedDistIndices数组
        定义字典classCount用来记录类别次数
        for i in 0-k:
            返回sortedDistIndices第i名位置的元素的类别
            设置字典,如果没有这个类:新建类,并设置value为1;否则将其value+1
        调用sorted语句对字典按照value降序排序
        返回次数最多的类别
    ```

* 文件 -> 数据矩阵 + 特征向量数组

  ```python
  def file2matrix(filename):
      #打开文件
      fr = open(filename)
      #读取文件所有内容
      arrayOfLines = fr.readlines()
      #得到文件行数
      numberOfLines = len(arrayOfLines)
      #返回的NumPy矩阵,解析完成的数据:numberOfLines行,3列
      returnMat = np.zeros((numberOfLines,3))
      #返回的分类标签向量
      classLabelVector = []
      #行的索引值
      index = 0
      for line in arrayOLines:
          #s.strip(rm)，当rm空时,默认删除空白符(包括'\n','\r','\t',' ')
          line = line.strip()
          #使用s.split(str="",num=string,cout(str))将字符串根据'\t'分隔符进行切片。
          listFromLine = line.split('\t')
          #将数据前三列提取出来,存放到returnMat的NumPy矩阵中,也就是特征矩阵
          returnMat[index,:] = listFromLine[0:3]
          #根据文本中标记的喜欢的程度进行分类,1代表不喜欢,2代表魅力一般,3代表极具魅力
          if listFromLine[-1] == 'didntLike':
              classLabelVector.append(1)
          elif listFromLine[-1] == 'smallDoses':
              classLabelVector.append(2)
          elif listFromLine[-1] == 'largeDoses':
              classLabelVector.append(3)
          index += 1
      return returnMat, classLabelVector
  ```

  * 伪代码

    ```python
    def file2matrix(filename):
        打开文件
        将文件按照行读取,每行存成一个array,形成一个列表
        得到文件行数
        根据矩阵行数新建矩阵行数 * 3的numpy零矩阵
        初始化分类的标签向量列表
        初始化行的索引值
        for 行 in 读取文件的内容构成的列表:
            删除line前后的空格
            使用'\t'字符将每行的内容分成四份,前三份分别对一个三个特征维度
            将矩阵的index行的内容设置特征维度的对应值
            根据最后一份的内容设置标签向量对应位置的值
            index += 1
        返回矩阵, 标签向量列表
    ```

* 数据矩阵 + 特征向量数组 -> 可视化数据

  ```python
  def showdatas(datingDataMat, datingLabels):
      #设置汉字格式
      font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)
      #将fig画布分隔成1行1列,不共享x轴和y轴,fig画布的大小为(13,8)
      #当nrow=2,nclos=2时,代表fig画布被分为四个区域,axs[0][0]表示第一行第一个区域
      fig, axs = plt.subplots(nrows=2, ncols=2,sharex=False, sharey=False, figsize=(13,8))

      numberOfLabels = len(datingLabels)
      LabelsColors = []
      for i in datingLabels:
          if i == 1:
              LabelsColors.append('black')
          if i == 2:
              LabelsColors.append('orange')
          if i == 3:
              LabelsColors.append('red')
      #画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第二列(玩游戏)数据画散点数据,散点大小为15,透明度为0.5
      axs[0][0].scatter(x=datingDataMat[:,0], y=datingDataMat[:,1], color=LabelsColors,s=15, alpha=.5)
      #设置标题,x轴label,y轴label
      axs0_title_text = axs[0][0].set_title(u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比',FontProperties=font)
      axs0_xlabel_text = axs[0][0].set_xlabel(u'每年获得的飞行常客里程数',FontProperties=font)
      axs0_ylabel_text = axs[0][0].set_ylabel(u'玩视频游戏所消耗时间占',FontProperties=font)
      plt.setp(axs0_title_text, size=9, weight='bold', color='red')
      plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')
      plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')

      #画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5
      axs[0][1].scatter(x=datingDataMat[:,0], y=datingDataMat[:,2], color=LabelsColors,s=15, alpha=.5)
      #设置标题,x轴label,y轴label
      axs1_title_text = axs[0][1].set_title(u'每年获得的飞行常客里程数与每周消费的冰激淋公升数',FontProperties=font)
      axs1_xlabel_text = axs[0][1].set_xlabel(u'每年获得的飞行常客里程数',FontProperties=font)
      axs1_ylabel_text = axs[0][1].set_ylabel(u'每周消费的冰激淋公升数',FontProperties=font)
      plt.setp(axs1_title_text, size=9, weight='bold', color='red')
      plt.setp(axs1_xlabel_text, size=7, weight='bold', color='black')
      plt.setp(axs1_ylabel_text, size=7, weight='bold', color='black')

      #画出散点图,以datingDataMat矩阵的第二(玩游戏)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5
      axs[1][0].scatter(x=datingDataMat[:,1], y=datingDataMat[:,2], color=LabelsColors,s=15, alpha=.5)
      #设置标题,x轴label,y轴label
      axs2_title_text = axs[1][0].set_title(u'玩视频游戏所消耗时间占比与每周消费的冰激淋公升数',FontProperties=font)
      axs2_xlabel_text = axs[1][0].set_xlabel(u'玩视频游戏所消耗时间占比',FontProperties=font)
      axs2_ylabel_text = axs[1][0].set_ylabel(u'每周消费的冰激淋公升数',FontProperties=font)
      plt.setp(axs2_title_text, size=9, weight='bold', color='red')
      plt.setp(axs2_xlabel_text, size=7, weight='bold', color='black')
      plt.setp(axs2_ylabel_text, size=7, weight='bold', color='black')
      #设置图例
      didntLike = mlines.Line2D([], [], color='black', marker='.', markersize=6, label='didntLike')
      smallDoses = mlines.Line2D([], [], color='orange', marker='.', markersize=6, label='smallDoses')
      largeDoses = mlines.Line2D([], [], color='red', marker='.', markersize=6, label='largeDoses')
      #添加图例
      axs[0][0].legend(handles=[didntLike,smallDoses,largeDoses])
      axs[0][1].legend(handles=[didntLike,smallDoses,largeDoses])
      axs[1][0].legend(handles=[didntLike,smallDoses,largeDoses])
      #显示图片
      plt.show()
  ```

  * 伪代码

    ```python
    def showdatas(datingDataMat, datingLabels):
        使用matplotlib中的FontProperties类新建中文字体font
        将画布axs分割成两行两列,分成四个区域,不共享x轴和y轴
        获得标签向量列表的行数
        初始化颜色标签列表
        for i in 标签向量列表:
            根据i的值在颜色标签列表的对应位置上设置不同颜色
        在axs[0][0]位置以矩阵第一列为横轴,矩阵第二列为纵轴,颜色取值为颜色标签列表画图
        使用set_title,set_xlabel,set_ylabel方法设置此位置矩阵的标题和x,y轴单位
        使用setp方法设置字的大小和颜色
        分别对ax[0][1], axs[1][0]两个位置都重复上述过程(分别以1,3列为x,y轴和2,3列为x,y轴)
        设置图例和添加图例
    ```

* 对数据进行归一化

  ```python
  def autoNorm(dataSet):
      #获得数据的最小值
      minVals = dataSet.min(0)
      maxVals = dataSet.max(0)
      #最大值和最小值的范围
      ranges = maxVals - minVals
      #shape(dataSet)返回dataSet的矩阵行列数
      normDataSet = np.zeros(np.shape(dataSet))
      #返回dataSet的行数
      m = dataSet.shape[0]
      #原始值减去最小值
      normDataSet = dataSet - np.tile(minVals, (m, 1))
      #除以最大和最小值的差,得到归一化数据
      normDataSet = normDataSet / np.tile(ranges, (m, 1))
      #返回归一化数据结果,数据范围,最小值
      return normDataSet, ranges, minVals
  ```

  * 伪代码

    ```python
    def autoNorm(dataSet):
        调用min(0),max(0)获得每一列的最大最小元素向量
        最大最小元素相减获得每一列的最大最小之间的range向量
        根据dataSet的大小初始化normDataSet
        获得dataSet矩阵的行数
        normDataSet = dataSet - 最小元素向量tile m行出来的矩阵(最小值矩阵)
        normDataSet = normDataset / range向量 tile m行出来的矩阵(范围矩阵)
        返回 归一化矩阵, 范围向量, 最小值向量
    ```

* 分类器测试函数

  ```python
  def datingClassTest():
      #打开的文件名
      filename = "datingTestSet.txt"
      #将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中
      datingDataMat, datingLabels = file2matrix(filename)
      #取所有数据的百分之十
      hoRatio = 0.10
      #数据归一化,返回归一化后的矩阵,数据范围,数据最小值
      normMat, ranges, minVals = autoNorm(datingDataMat)
      #获得normMat的行数
      m = normMat.shape[0]
      #百分之十的测试数据的个数
      numTestVecs = int(m * hoRatio)
      #分类错误计数
      errorCount = 0.0

      for i in range(numTestVecs):
          #前numTestVecs个数据作为测试集,后m-numTestVecs个数据作为训练集
          classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:],
              datingLabels[numTestVecs:m], 4)
          print("分类结果:%d\t真实类别:%d" % (classifierResult, datingLabels[i]))
          if classifierResult != datingLabels[i]:
              errorCount += 1.0
      print("错误率:%f%%" %(errorCount/float(numTestVecs)*100))
  ```

  * 伪代码

    ```python
    def datingClassTest():
        初始化文件名
        调用file2matrix函数从文件中读取矩阵和标签向量
        设置测试集所占比例
        调用autoNorm函数将矩阵归一化
        m = 矩阵行数
        numTestVecs = m * 测试集所占比例
        初始化错误数量
        for i in numTestVecs:
            classifierResult = 调用classify0函数进行测试
            if 预测结果 != 真实结果:
                错误数量 ++
        print(错误数量)
    ```

* 最终函数

  ```python
  def classifyPerson():
      #输出结果
      resultList = ['讨厌','有些喜欢','非常喜欢']
      #三维特征用户输入
      precentTats = float(input("玩视频游戏所耗时间百分比:"))
      ffMiles = float(input("每年获得的飞行常客里程数:"))
      iceCream = float(input("每周消费的冰激淋公升数:"))
      #打开的文件名
      filename = "datingTestSet.txt"
      #打开并处理数据
      datingDataMat, datingLabels = file2matrix(filename)
      #训练集归一化
      normMat, ranges, minVals = autoNorm(datingDataMat)
      #生成NumPy数组,测试集
      inArr = np.array([ffMiles, precentTats, iceCream])
      #测试集归一化
      norminArr = (inArr - minVals) / ranges
      #返回分类结果
      classifierResult = classify0(norminArr, normMat, datingLabels, 3)
      #打印结果
      print("你可能%s这个人" % (resultList[classifierResult-1]))
  ```

  * 伪代码

    ```python
    def classifyPerson():
        设置输出结果列表
        获取用户输入的三维特征变量的值
        初始化文件名
        调用file2matrix函数从文件中读取矩阵和标签向量
        调用autoNorm函数将矩阵归一化,返回归一化矩阵,范围向量,最小值向量
        将用户输入的三维变量转化成np.array构成的向量inArr
        (inArr - 最小值向量) / 范围向量 来归一化用户输入向量
        调用classify0函数来预测结果
        输出结果
    ```

* kNN-sklearn-minst: 将二进制图像转换为向量

  ```python
  def img2vector(filename):
      #创建1x1024零向量
      returnVect = np.zeros((1, 1024))
      #打开文件
      fr = open(filename)
      #按行读取
      for i in range(32):
          #读一行数据
          lineStr = fr.readline()
          #每一行的前32个元素依次添加到returnVect中
          for j in range(32):
              returnVect[0, 32*i+j] = int(lineStr[j])
      #返回转换后的1x1024向量
      return returnVect
  ```

  * 伪代码

    ```python
    def img2vector(filename):
        创建1*1024的空向量returnVect
        打开需要读取的文件
        for i in 所有行:
            使用readline()方法读取u下一行的数据
            for j in 此行的所有数字:
                returnVect[0, 32 * 行 + 列] = int(此处的数字)
        返回returnVect
    ```

* kNN-sklearn-minst: 手写数字分类测试

  ```python
  def handwritingClassTest():
      #测试集的Labels
      hwLabels = []
      #返回trainingDigits目录下的文件名
      trainingFileList = listdir('trainingDigits')
      #返回文件夹下文件的个数
      m = len(trainingFileList)
      #初始化训练的Mat矩阵,测试集
      trainingMat = np.zeros((m, 1024))
      #从文件名中解析出训练集的类别
      for i in range(m):
          #获得文件的名字
          fileNameStr = trainingFileList[i]
          #获得分类的数字
          classNumber = int(fileNameStr.split('_')[0])
          #将获得的类别添加到hwLabels中
          hwLabels.append(classNumber)
          #将每一个文件的1x1024数据存储到trainingMat矩阵中
          trainingMat[i,:] = img2vector('trainingDigits/%s' % (fileNameStr))
      #构建kNN分类器
      neigh = kNN(n_neighbors = 3, algorithm = 'auto')
      #拟合模型, trainingMat为训练矩阵,hwLabels为对应的标签
      neigh.fit(trainingMat, hwLabels)
      #返回testDigits目录下的文件列表
      testFileList = listdir('testDigits')
      #错误检测计数
      errorCount = 0.0
      #测试数据的数量
      mTest = len(testFileList)
      #从文件中解析出测试集的类别并进行分类测试
      for i in range(mTest):
          #获得文件的名字
          fileNameStr = testFileList[i]
          #获得分类的数字
          classNumber = int(fileNameStr.split('_')[0])
          #获得测试集的1x1024向量,用于训练
          vectorUnderTest = img2vector('testDigits/%s' % (fileNameStr))
          #获得预测结果
          # classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)
          classifierResult = neigh.predict(vectorUnderTest)
          print("分类返回结果为%d\t真实结果为%d" % (classifierResult, classNumber))
          if(classifierResult != classNumber):
              errorCount += 1.0
      print("总共错了%d个数据\n错误率为%f%%" % (errorCount, errorCount/mTest * 100))
  ```

  * 伪代码

    ```python
    def handwritingClassTest():
        初始化训练集的标签向量
        调用listdir()函数将训练集下的所有文件名存储至trainingFileList列表中
        获取训练集的文件个数
        根据文件个数创建空的特征矩阵(文件个数 * 1024)
        for i in 文件个数:
            获得trainingFileList[i]的文件名
            使用'_'分割文件名来获取此文件表示的数字(标签)
            将获得的标签添加到标签向量的末尾
            特征矩阵第i行 = img2vector(训练集下的这个文件的路径)
        调用sklearn包,新建kNN分类器neigh,查找算法设置为auto
        调用neigh.fit()方法来拟合出分类器
        调用listdir()函数将测试集下的所有文件名存储至testFileList列表中
        初始化错误数量
        获得测试集文件个数
        for i in 测试集文件个数:
            获得testFileList[i]的文件名
            使用'_'分割文件名来获取此文件表示的数字(标签)
            此文件特征向量 = img2vector(测试集下的这个文件的路径)
            分类结果 = neigh.predict(此文件特征向量)
            输出分类结果和真实结果
            if 两个结果不相等:
                错误数量++
            输出错误率
    ```



## 决策树算法

* 计算经验熵(使用特征分割前的数据集的熵)

  ```python
  def createDataSet():
      dataSet = [[0, 0, 0, 0, 'no'],         #数据集
              [0, 0, 0, 1, 'no'],
              [0, 1, 0, 1, 'yes'],
              [0, 1, 1, 0, 'yes'],
              [0, 0, 0, 0, 'no'],
              [1, 0, 0, 0, 'no'],
              [1, 0, 0, 1, 'no'],
              [1, 1, 1, 1, 'yes'],
              [1, 0, 1, 2, 'yes'],
              [1, 0, 1, 2, 'yes'],
              [2, 0, 1, 2, 'yes'],
              [2, 0, 1, 1, 'yes'],
              [2, 1, 0, 1, 'yes'],
              [2, 1, 0, 2, 'yes'],
              [2, 0, 0, 0, 'no']]
      labels = ['不放贷', '放贷']             #分类属性
      return dataSet, labels
  def calcShannonEnt(dataSet):
      numEntires = len(dataSet)                        #返回数据集的行数
      labelCounts = {}                                #保存每个标签(Label)出现次数的字典
      for featVec in dataSet:                            #对每组特征向量进行统计
          currentLabel = featVec[-1]                    #提取标签(Label)信息
          if currentLabel not in labelCounts.keys():    #如果标签(Label)没有放入统计次数的字典,添加进去
              labelCounts[currentLabel] = 0
          labelCounts[currentLabel] += 1                #Label计数
      shannonEnt = 0.0                                #经验熵(香农熵)
      for key in labelCounts:                            #计算香农熵
          prob = float(labelCounts[key]) / numEntires    #选择该标签(Label)的概率
          shannonEnt -= prob * log(prob, 2)            #利用公式计算
      return shannonEnt                                #返回经验熵(香农熵)
  ```

  * 伪代码

    ```python
    def createDataSet():
        生成数据集二维列表和标签属性列表
    def calcShannonEnt(dataSet):
        获取数据集的行数
        新建保存每个标签(类别)出现次数的字典
        for 特征向量 in 数据集二维列表:
            提取特征向量最后一位的标签信息
            if 此标签 not in 字典.keys():
                字典[此标签] = 0
            字典[此标签] += 1
        初始化经验熵为0
        for key in 字典:
            此标签的概率 = float(此标签出现次数 / 数据集行数)
            经验熵 -= 此标签概率 * log(此标签概率, 2)
        返回经验熵
    ```

* 按照给定的特征划分数据集

  ```python
  def splitDataSet(dataSet, axis, value):       
      retDataSet = []                                        #创建返回的数据集列表
      for featVec in dataSet:                             #遍历数据集
          if featVec[axis] == value:
              reducedFeatVec = featVec[:axis]                #去掉axis特征
              reducedFeatVec.extend(featVec[axis+1:])     #将符合条件的添加到返回的数据集
              retDataSet.append(reducedFeatVec)
      return retDataSet                                      #返回划分后的数据集
  ```

  * 伪代码

    ```python
    def splitDataSet(dataSet, axis, value):  
        初始化返回的数据集列表
        for 特征向量 in 数据集:
            if 特征向量给定轴取值 == value:
                reducedFeatVec = 去掉这个轴之后的特征向量(extend方法注意)
                将reducedFeatVec添加到返回的数据集列表末尾
        返回数据集列表(已划分)
    ```

* 选择最优特征(信息增益)

  ```python
  def chooseBestFeatureToSplit(dataSet):
      numFeatures = len(dataSet[0]) - 1                    #特征数量
      baseEntropy = calcShannonEnt(dataSet)                 #计算数据集的香农熵
      bestInfoGain = 0.0                                  #信息增益
      bestFeature = -1                                    #最优特征的索引值
      for i in range(numFeatures):                         #遍历所有特征
          #获取dataSet的第i个所有特征
          featList = [example[i] for example in dataSet]
          uniqueVals = set(featList)                         #创建set集合{},元素不可重复
          newEntropy = 0.0                                  #经验条件熵
          for value in uniqueVals:                         #计算信息增益
              subDataSet = splitDataSet(dataSet, i, value)         #subDataSet划分后的子集
              prob = len(subDataSet) / float(len(dataSet))           #计算子集的概率
              newEntropy += prob * calcShannonEnt(subDataSet)     #根据公式计算经验条件熵
          infoGain = baseEntropy - newEntropy                     #信息增益
          print("第%d个特征的增益为%.3f" % (i, infoGain))            #打印每个特征的信息增益
          if (infoGain > bestInfoGain):                             #计算信息增益
              bestInfoGain = infoGain                             #更新信息增益，找到最大的信息增益
              bestFeature = i                                     #记录信息增益最大的特征的索引值
      return bestFeature
  ```

  * 伪代码

    ```python
    def chooseBestFeatureToSplit(dataSet):
        获取特征个数
        计算并获取当前数据集的经验熵
        初始化最优信息增益为0
        初始化最优特征索引值为-1
        for i in 特征个数:
            featList = 数据集中所有特征向量在i上的取值构成的列表
            uniqueVals = 集合化(featList),取得i的所有可能取值的集合
            本特征信息增益 = 0
            for 每个取值 in uniqueVals:
                subDataSet = 数据集在特征i的这个取值下的子集
                这个取值的子集的概率 = 子集长度 / 数据集长度
                本特征条件熵 += 这个取值的子集的概率 * 本子集的经验熵
            本特征信息增益 = 经验熵 - 本特征条件熵
            输出本特征信息增益
            if 本特征信息增益 > 最佳信息增益:
                更新最佳信息增益和最优特征索引值
        返回最优特征索引值
    ```

* 选择最优特征(信息增益率)

  ```python
  def calIntrinsicValue(dataset):
      numFeature = len(dataset[0]) - 1
      intrinsicValue = []
      for i in range(numFeature):
          featList = [example[i] for example in dataset]
          uniqueVals = set(featList)
          thisIntrinsicValue = 0.0
          for value in uniqueVals:
              subDataSet = splitDataSet(dataset, i, value)
              prob = len(subDataSet) / float(len(dataset))
              thisIntrinsicValue -= prob * log(prob, 2)
          intrinsicValue.append(thisIntrinsicValue)
      return intrinsicValue
  ```

  ```python
  def chooseBestFeatureToSplit_0(dataset):
      numFeatures = len(dataset[0]) - 1
      baseEntropy = calcShannonEnt(dataset)
      infoGainList = []
      totalInfoGain = 0.0
      bestFeature = -1
      intrinsicValueList = calIntrinsicValue(dataset)
      for i in range(numFeatures):
          featList = [example[i] for example in dataset]
          uniqueVals = set(featList)
          newEntropy = 0.0
          for value in uniqueVals:
              subDataset = splitDataSet(dataset, i, value)
              prob = len(subDataset) / float(len(dataset))
              newEntropy += prob * calcShannonEnt(subDataset)
          infoGain = baseEntropy - newEntropy
          # 输出并更新信息增益的最优值
          print(f"第{i}个特征的增益为: {infoGain}")
          infoGainList.append(infoGain)
          totalInfoGain += infoGain
      averageInfoGain = totalInfoGain / float(numFeatures)
      bestGainRatio = 0.0
      for i in range(len(infoGainList)):
          print(f'最优增益率为: {bestGainRatio}')
          gainRatio = 0.0
          if infoGainList[i] > averageInfoGain:
              gainRatio = float(infoGainList[i]) / intrinsicValueList[i]
              print(f"第{i}个特征的增益率为: {gainRatio}")
          if gainRatio > bestGainRatio:
              bestFeature = i
              bestGainRatio = gainRatio
      print(f'最优特征取值为: {bestFeature}')
      return bestFeature
  ```

  * 伪代码

    ```python
    def calIntrinsicValue(dataset):
        获得特征变量个数
        新建固有值列表
        for i in 特征变量个数:
            featList = 数据集中所有特征向量在i上的取值构成的列表
            uniqueVals = 集合化(featList)
            初始化本特征向量固有值 = 0.0
            for value in 本特征向量的所有取值:
                subDataSet = 数据集在特征i的value取值下的子集
                prob = 子集长度 / 总集合长度
                本特征向量固有值 -= prob * log(prob,2)
            将本向量固有值添加到固有值列表
        返回固有值列表
     def chooseBestFeatureToSplit_0(dataset):
        获得特征变量个数
        计算并获取当前数据集的经验熵
        初始化信息增益列表
        初始化总增益
        初始化最优特征索引值
        调用calIntrinsicValue()获得固有值列表
        for i in 特征变量个数:
            featList = 数据集中所有特征向量在i上的取值构成的列表
            uniqueVals = 集合化(featList)
            初始化本特征条件熵
            for value in 本特征的所有取值:
                subDataSet = 数据集在特征i的value取值下的子集
                prob = 子集长度 / 总集合长度
                本特征条件熵 += prob * 本子集的经验熵
            本特征信息增益 = 数据集经验熵 - 本特征条件熵
            将本特征信息增益插入信息增益列表末尾
            更新总信息增益
        平均信息增益 = 总信息增益 / 特征数量
        初始化最佳信息增益率
        for i in 特征变量个数:
            初始化信息增益率
            if 特征i的信息增益 > 平均信息增益:
                信息增益率 = 特征i的信息增益 / 特征i的固有值
            if 信息增益率 > 最佳信息增益率:
                更新最优特征的索引值
                最优信息增益率 = 信息增益率
        返回最优特征索引值
    ```

* 统计出现次数最多的类别标签

  ```python
  def majorityCnt(classList):
      classCount = {}
      for vote in classList:
          if vote not in classCount.keys():classCount[vote] = 0   
          classCount[vote] += 1
      sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)
      return sortedClassCount[0][0]
  ```

  * 伪代码

    ```python
    def majorityCnt(classList):
        新建classCount字典
        for vote in 标签向量列表:
            if vote not in classCount的键:
                设置vote的键为0
            vote键对应的值 += 1
        sortedClassCount = 调用sorted函数对字典按照值的降序排序,返回二维列表
        返回sortedClassCount的最大值的对应键    
    ```

* 创建决策树

  ```python
  def createTree(dataSet, labels, featLabels):
      classList = [example[-1] for example in dataSet]#取分类标签(是否放贷:yes or no)
      if classList.count(classList[0]) == len(classList):#如果类别完全相同则停止继续划分
          return classList[0]
      if len(dataSet[0]) == 1:#遍历完所有特征时返回出现次数最多的类标签
          return majorityCnt(classList)
      bestFeat = chooseBestFeatureToSplit(dataSet)#选择最优特征
      bestFeatLabel = labels[bestFeat]#最优特征的标签
      featLabels.append(bestFeatLabel)
      myTree = {bestFeatLabel:{}}#根据最优特征的标签生成树
      del(labels[bestFeat])#删除已经使用特征标签
      featValues = [example[bestFeat] for example in dataSet]#得到训练集中所有最优特征的属性值
      uniqueVals = set(featValues)#去掉重复的属性值
      for value in uniqueVals:#遍历特征，创建决策树。                       
          myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), labels, featLabels)
      return myTree
  ```

  * 伪代码

    ```python
    def createTree(dataSet, labels, featLabels):
        从数据集中获取分类标签向量列表classList
        # 以下是递归的停止条件(可用特征没了, 数据集统一了)
        if classList中与classList[0]相等的数量 = classList长度:
            返回classList[0]
        if 数据集只有一维(特征全部被划分完了):
            调用majorityCnt()函数返回此时出现次数最多的类别
        调用chooseBestFeatureToSplit()函数返回最优特征索引值
        根据这个索引值在labels中找到对应的特征bestFeatLabel
        将bestFeatLabel添加到featLabels末尾
        利用字典的数据结构新建根节点为bestFeatLabel的树myTree
        删除labels中的bestLabels标签
        获得数据集中bestFeatLabel的所有特征并将其集合化为uniqueVals
        for value in uniqueVals(最优特征的每一个取值):
            myTree[最有特征][value] = createTree(删去最优特征value取值数据的数据集,labels, featLabels)
        返回myTree
    ```

* 使用决策树进行分类

  ```python
  def classify(inputTree, featLabels, testVec):
      firstStr = next(iter(inputTree))                                                        #获取决策树结点
      secondDict = inputTree[firstStr]                                                        #下一个字典
      featIndex = featLabels.index(firstStr)                                               
      for key in secondDict.keys():
          if testVec[featIndex] == key:
              if type(secondDict[key]).__name__ == 'dict':
                  classLabel = classify(secondDict[key], featLabels, testVec)
              else: classLabel = secondDict[key]
      return classLabel
  ```

  * 伪代码

    ```python
    def classify(inputTree, featLabels, testVec):
        获得树的根节点(字典的键)
        根据根节点获取其对应的值(第二层字典)
        根据根节点的值获取其在featLabels中的索引位置i
        for key in 第二层字典中的所有键(也就是根节点的所有可能取值):
            if 输入向量的i位置的值 == key:
                if 第二层字典中键key的对应值是字典:
                    classLabel = classify(第二层字典[key], featLabels, 输入向量)
                else:
                    classLabel = 第二层字典[key]
        返回classLabels
    ```

* 存储和调用决策树

  ```python
  def storeTree(inputTree, filename):
      with open(filename, 'wb') as fw:
          pickle.dump(inputTree, fw)
  def grabTree(filename):
      fr = open(filename, 'rb')
      return pickle.load(fr)
  ```

  * 伪代码

    ```python
    # pickle.dump(对象, 文件对象)
    # pickle.load(文件对象)
    ```

* sklearn+决策树+UCI database ->数据处理

  ```python
  import pandas as pd
  if __name__ == '__main__':
      with open('lenses.txt', 'r') as fr:
          lenses = [inst.strip().split('\t') for inst in fr.readlines()]
      lenses_target = []
      for each in lenses:
          lenses_target.append(each[-1])

      lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']       
      lenses_list = []
      lenses_dict = {}
      for each_label in lensesLabels:
          for each in lenses:
              lenses_list.append(each[lensesLabels.index(each_label)])
          lenses_dict[each_label] = lenses_list
          lenses_list = []
      print(lenses_dict)
      lenses_pd = pd.DataFrame(lenses_dict)
      print(lenses_pd)
      le = LabelEncoder()           
      for col in lenses_pd.columns:
          lenses_pd[col] = le.fit_transform(lenses_pd[col])
      print(lenses_pd)
  ```

  * 伪代码

    ```python
    导入pandas包为pd
    打开文件为文件对象
    lenses = 将文件中的数据导入并解析为二元数组
    初始化标签向量列表
    for 每一组数据 in lenses:
        将每一组数据的最后一个添加进标签向量列表
    新建lenseLabel存储特征变量的名字
    初始化特征值列表和特征字典
    for 每一个特征值 in lenseLabel:
        for 每一组数据 in lenses:
            将每组数据的这个特征值对应位置的取值添加到特征值列表
        特征字典[这个特征值的名字] = 特征值列表
        清空特征值列表
    lense_pd = 将特征字典转化为pandas.dataFrame
    新建标签编码类LabelEncoder(将字符串标签(yes, no)转换为数字标签(0, 1))
    for 每一列 in lense_pd.columns:
        lense_pd[col] = 调用fit_transform()方法来编码为数字
    ```




## 朴素贝叶斯分类器

* 载入数据

  ```python
  def loadDataSet():
      postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],               
                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],
                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]
      classVec = [0,1,0,1,0,1]                                                                
      return postingList,classVec
  ```

  * 伪代码

    ```python
    def loadDataSet():
        初始化词条列表
        初始化词条类别向量
        返回两个对象
    ```

* 实验样本词条 -> 不重复的词汇表

  ```python
  def createVocabList(dataSet):
      vocabSet = set([])
      for document in dataSet:               
          vocabSet = vocabSet | set(document)
      return list(vocabSet)
  ```

  * 伪代码

    ```python
    def createVocabList(dataSet):
        初始化词汇表空集合
        for 每个词条 in 数据集:
            词汇表 = 词汇表 并 集合化(词条)
        返回 列表化(词汇表)
    ```

* 根据词汇表, 将词条转换为词条向量

  ```python
  def setOfWords2Vec(vocabList, inputSet):
      returnVec = [0] * len(vocabList)
      for word in inputSet:
          if word in vocabList:
              returnVec[vocabList.index(word)] = 1
          else: print("the word: %s is not in my Vocabulary!" % word)
      return returnVec
  ```

  * 伪代码

    ```python
    def setOfWords2Vec(vocabList, inputSet):
        初始化空词条向量(初值全为0)
        for 单词 in 词条(inputSet):
            if 单词 in 词汇表:
                词条向量[单词在词汇表中的位置] = 1
            else:
                啥也不做
        返回词条向量
    ```

* 朴素贝叶斯分类器训练函数

  ```python
  def trainNB0(trainMatrix,trainCategory):
      numTrainDocs = len(trainMatrix)
      numWords = len(trainMatrix[0])
      pAbusive = sum(trainCategory)/float(numTrainDocs)
      p0Num = np.zeros(numWords); p1Num = np.zeros(numWords)
      p0Denom = 0.0; p1Denom = 0.0
      for i in range(numTrainDocs):
          if trainCategory[i] == 1:
              p1Num += trainMatrix[i]
              p1Denom += sum(trainMatrix[i])
          else:
              p0Num += trainMatrix[i]
              p0Denom += sum(trainMatrix[i])
      p1Vect = p1Num/p1Denom                                      
      p0Vect = p0Num/p0Denom         
      return p0Vect,p1Vect,pAbusive
  ```

  * 伪代码

    ```python
    def trainNB0(trainMatrix,trainCategory):
        获得词条向量的数量
        获得词条向量的词数
        侮辱性词条向量的概率 = 侮辱性词条向量的总数 / 词条向量的数量
        初始化词频向量(非侮辱性)和词频向量(侮辱性)
        初始化词总数(非侮辱性)和词总数(侮辱性)
        for 每一条词条向量 in 词条向量矩阵:
            if trainCategory显示这条词条向量为非侮辱性:
                词频向量(非侮辱性) += 这条词条向量
                词总数(非侮辱性) += 词条向量里包含的词数
            else:
                词频向量(侮辱性) += 这条词条向量
                词总数(侮辱性) += 词条向量里包含的词数
        词概率向量(非侮辱性) = 词频向量(非侮辱性) / 词总数(非侮辱性)
        词概率向量(侮辱性) = 词频向量(侮辱性) / 词总数(侮辱性)
        返回两个词概率向量和侮辱性词条向量的概率
    ```

* 朴素贝叶斯分类器训练函数(拉普拉斯平滑, 乘积结果取对数防止下溢出)

  ```python
  def trainNB0(trainMatrix,trainCategory):
      numTrainDocs = len(trainMatrix)#计算训练的文档数目
      numWords = len(trainMatrix[0])#计算每篇文档的词条数
      pAbusive = sum(trainCategory)/float(numTrainDocs)#文档属于侮辱类的概率
      p0Num = np.ones(numWords); p1Num = np.ones(numWords)#创建numpy.ones数组,词条出现数初始化为1，拉普拉斯平滑
      p0Denom = 2.0; p1Denom = 2.0#分母初始化为2,拉普拉斯平滑
      for i in range(numTrainDocs):
          if trainCategory[i] == 1:#统计属于侮辱类的条件概率所需的数据，即P(w0|1),P(w1|1),P(w2|1)
              p1Num += trainMatrix[i]
              p1Denom += sum(trainMatrix[i])
          else:#统计属于非侮辱类的条件概率所需的数据，即P(w0|0),P(w1|0),P(w2|0)
              p0Num += trainMatrix[i]
              p0Denom += sum(trainMatrix[i])
      p1Vect = np.log(p1Num/p1Denom)#取对数，防止下溢出         
      p0Vect = np.log(p0Num/p0Denom)         
      return p0Vect,p1Vect,pAbusive
  ```

  * 伪代码

    ```python
    def trainNB0(trainMatrix,trainCategory):
        获得词条向量的数量
        获得词条向量的词数
        侮辱性词条向量的概率 = 侮辱性词条向量的总数 / 词条向量的数量
        初始化词频向量(非侮辱性)和词频向量(侮辱性)(默认出现次数为1)
        初始化词总数(非侮辱性)和词总数(侮辱性)(默认使得不出现的词的词概率为50%, 默认词总数为2)
        for 每一条词条向量 in 词条向量矩阵:
            if trainCategory显示这条词条向量为非侮辱性:
                词频向量(非侮辱性) += 这条词条向量
                词总数(非侮辱性) += 词条向量里包含的词数
            else:
                词频向量(侮辱性) += 这条词条向量
                词总数(侮辱性) += 词条向量里包含的词数
        词概率向量(非侮辱性) = log(词频向量(非侮辱性) / 词总数(非侮辱性))
        词概率向量(侮辱性) = log(词频向量(侮辱性) / 词总数(侮辱性))
        返回两个词概率向量和侮辱性词条向量的概率
    ```

* 朴素贝叶斯分类器分类函数

  ```python
  def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):
      p1 = sum(vec2Classify * p1Vec) + np.log(pClass1)#对应元素相乘。logA * B = logA + logB，所以这里加上log(pClass1)
      p0 = sum(vec2Classify * p0Vec) + np.log(1.0 - pClass1)
      if p1 > p0:
          return 1
      else:
          return 0
  ```

  * 伪代码

    ```python
    def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):
        词条为侮辱性的概率(取对数) = 相加求和(词条向量 * 词概率向量(侮辱性))+log(侮辱性出现概率)
        词条为非侮辱性的概率(对数) = 相加求和(词条向量 * 词概率向量(非侮辱))+log(非侮辱出现概率)
        if 侮辱性的概率(取对数):
            返回1
        else:
            返回0
    ```

* 将英文句子切分成英文词条
  ```python
  import re
  def textParse(bigString):
    listOfTokens = re.split(r'\W*', bigString)
    return [tok.lower() for tok in listOfTokens if len(tok) > 2]
  ```
  * 伪代码
    ```python
    def textParse(bigString):
      将英文句子使用正则表达式按照特殊符号分开并存储于listOfTokens数组
      返回listOfTokens中长度大于等于2的词组成的数组
    ```
* 垃圾邮件预测
  ```python
  def spamTest():
    docList = []; classList = []
    for i in range(1, 26):
        wordList = textParse(open('email/spam/%d.txt' % i, 'r').read())
        docList.append(wordList)
        classList.append(1)
        wordList = textParse(open('email/ham/%d.txt' % i, 'r').read())
        docList.append(wordList)
        classList.append(0)                                                  
    vocabList = createVocabList(docList)
    trainingSet = list(range(50)); testSet = []                       
    for i in range(10):
        randIndex = int(random.uniform(0, len(trainingSet)))
        testSet.append(trainingSet[randIndex])
        del(trainingSet[randIndex])
    trainMat = []; trainClasses = []            
    for docIndex in trainingSet:
        trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))
        trainClasses.append(classList[docIndex])
    p0V, p1V, pSpam = trainNB0(np.array(trainMat), np.array(trainClasses))
    errorCount = 0
    for docIndex in testSet:
        wordVector = setOfWords2Vec(vocabList, docList[docIndex])
        if classifyNB(np.array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:
            errorCount += 1
            print("分类错误的测试集：",docList[docIndex])
    print('错误率：%.2f%%' % (float(errorCount) / len(testSet) * 100))
  ```
  * 伪代码
    ```python
    def spamTest():
      初始化词条列表, 标签向量列表
      for i in 邮件数量:
        词条 = textParse(读取位置i的垃圾邮件的字符串)
        将词条添加到词条列表末尾
        标签向量列表末尾增加1
        词条 = textParse(读取位置i的普通邮件的字符串)
        将词条添加到词条列表末尾
        标签向量列表末尾增加0
      词汇表 = createVocabList(词条列表)
      初始化训练集序号列表(满)和测试集序号列表(空)
      for i in 训练集邮件数量:
        随机索引值 = int(random.uniform(0, 训练集当前长度))
        将训练集[随机索引值]添加到测试集
        删除训练集[随机索引值]
      初始化训练集特征矩阵(空)和训练集标签列表(空)
      for 索引值 in 训练集序号列表:
        将setOfWord2Vec(词汇表, 词条列表[索引值])的词条向量添加到特征矩阵
        将标签向量列表[索引值]添加到训练集标签列表
      词概率向量, 垃圾邮件概率 = 将特征矩阵和训练集标签列表用作训练
      初始化错误值
      for 索引值 in 测试集序号列表:
        词条向量 = setOfWord2Vec(词汇表, 词条列表[索引值])
        if 将词条列表导入分类得出结果 != 标签向量列表[索引值]:
          错误值 += 1
      输出错误率
    ```
* sklearn+NB+新浪新闻分类--分词
  ```python
  def TextProcessing(folder_path):
    folder_list = os.listdir(folder_path)
    data_list = []
    class_list = []
    for folder in folder_list:
        new_folder_path = os.path.join(folder_path, folder)
        files = os.listdir(new_folder_path)
        j = 1
        for file in files:
            if j > 100:
                break
            with open(os.path.join(new_folder_path, file), 'r', encoding = 'utf-8') as f:
                raw = f.read()
            word_cut = jieba.cut(raw, cut_all = False)
            word_list = list(word_cut)
            data_list.append(word_list)
            class_list.append(folder)
            j += 1
        print(data_list)
        print(class_list)
  ```
  * 伪代码
    ```python
      def TextProcessing(folder_path):
        子文件夹列表 = os.listdir(folder_path)
        初始化词条列表和标签向量列表
        for 子文件夹 in 子文件夹列表:
          新的文件夹路径 = os.path.join(folder_path, 子文件夹)
          文件列表 = os.listdir(新的文件夹路径)
          初始化文件数量 = 1
          for file in 文件列表:
            if 文件数量 > 100:
              跳出循环(保持每一类新闻数量<=100)
            with open(file, 可读) as f:
              未处理文本 = f.read()
            词条 = list(jieba.cut(未处理文本, cut_all = False))
            将词条添加到词条列表末尾
            将子文件夹名字添加到标签向量列表末尾
            文件数量 += 1
        输出
    ```
* sklearn+NB+新浪新闻分类--(接上 文本处理)
  ```python
  def TextProcessing(folder_path, , test_size = 0.2):
    data_class_list = list(zip(data_list, class_list))
    random.shuffle(data_class_list)
    index = int(len(data_class_list) * test_size) + 1
    train_list = data_class_list[index:]
    test_list = data_class_list[:index]
    train_data_list, train_class_list = zip(*train_list)
    test_data_list, test_class_list = zip(*test_list)

    all_words_dict = {}
    for word_list in train_data_list:
        for word in word_list:
            if word in all_words_dict.keys():
                all_words_dict[word] += 1
            else:
                all_words_dict[word] = 1
    all_words_tuple_list = sorted(all_words_dict.items(), key = lambda f:f[1], reverse = True)
    all_words_list, all_words_nums = zip(*all_words_tuple_list)
    all_words_list = list(all_words_list)
    return all_words_list, train_data_list, test_data_list, train_class_list, test_class_list
  ```
  * 伪代码
    ```python
    def TextProcessing(folder_path, test_size = 0.2):
      词条_标签列表 = 列表化(捆绑(词条向量列表, 标签列表))
      使用random.shuffle()方法来打乱词条_标签列表的顺序
      训练集切分的索引值 = int(列表长度 * 测试集占比) + 1
      训练集 = 词条_标签列表[索引值: ]
      测试集 = 词条_标签列表[0: 索引值]
      训练词条列表, 训练标签向量 = zip(*训练集)
      测试词条列表, 测试标签向量 = zip(*测试集)
      新建词频字典用来统计训练集里的词频
      for 词条 in 训练词条列表:
        for 词 in 词条:
          if 词 in 词频字典.keys():
            词频字典[词] += 1
          else:
            词频字典[词] = 1
      调用sorted()调用sorted函数对字典按照值的降序排序并输出二维列表
      词集列表(降序), 词频列表(降序) = zip(*降序词频二维列表)
      返回 词集列表, 训练词条列表, 测试词条列表, 训练标签向量, 测试标签向量
    ```
* sklearn+NB+新浪新闻分类--文本清洗
  ```python
  def words_dict(all_words_list, deleteN, stopwords_set = set()):
    feature_words = []
    n = 1
    for t in range(deleteN, len(all_words_list), 1):
        if n > 1000:
            break                               
        if not all_words_list[t].isdigit() and all_words_list[t] not in stopwords_set and 1 < len(all_words_list[t]) < 5:
            feature_words.append(all_words_list[t])
        n += 1   
    return feature_words
  ```
  * 伪代码
    ```python
    def words_dict(all_words_list, deleteN, stopwords_set = set()):
      初始化特征词集(词汇表)
      初始化特征维度 = 1
      for t in range(需要删除的高频词数, 词集列表的长度, 1):
        if 特征维度 > 1000:
          跳出循环
        if 词集列表[t]的词(不是数字 and 不在stopwords_set中 and 1 < 长度 < 5):
          将词集列表[t]添加到特征词集(词汇表)末尾
      返回特征词集(词汇表)
    ```
* sklearn+NB+新浪新闻分类--新闻分类器
  ```python
  def TextClassifier(train_feature_list, test_feature_list, train_class_list, test_class_list):
    classifier = MultinomialNB().fit(train_feature_list, train_class_list)
    test_accuracy = classifier.score(test_feature_list, test_class_list)
    return test_accuracy
  ```
  * 伪代码
    ```python
      def TextClassifier(train_feature_list, test_feature_list, train_class_list, test_class_list):
        使用sklearn中的MultinomialNB()类的fit()方法训练出分类器
        使用sklearn中的MultinomialNB()类的score()方法计算测试集的精确度
        返回 精确度
    ```
## Logistic回归算法(其实是分类算法)
* 加载数据集
  ```python
  def loadDataSet():
    dataMat = []                                                        #创建数据列表
    labelMat = []                                                        #创建标签列表
    fr = open('testSet.txt')                                            #打开文件   
    for line in fr.readlines():                                            #逐行读取
        lineArr = line.strip().split()                                    #去回车，放入列表
        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])        #添加数据
        labelMat.append(int(lineArr[2]))                                #添加标签
    fr.close()                                                            #关闭文件
    return dataMat, labelMat
  ```
  * 伪代码
    ```python
    def loadDataSet():
      初始化特征向量矩阵和标签向量列表
      打开文件为fr
      for 每一行 in fr.readlines():
        lineArr = 每一行.去掉前后多余字符().用默认间隔符分割成为列表()
        # 1.0相当于x0
        特征向量矩阵.添加([1.0, lineArr第一列特征, lineArr第二列特征])
        标签向量列表.添加(lineArr最后一列标签)
      fr.关闭()
      返回特征向量矩阵, 标签向量列表
    ```
* 绘制数据集
  ```python
  def plotDataSet():
    dataMat, labelMat = loadDataSet()
    dataArr = np.array(dataMat)
    n = np.shape(dataMat)[0]
    xcord1 = []; ycord1 = []
    xcord2 = []; ycord2 = []
    for i in range(n):
        if int(labelMat[i]) == 1:
            xcord1.append(dataArr[i,1]); ycord1.append(dataArr[i,2])
        else:
            xcord2.append(dataArr[i,1]); ycord2.append(dataArr[i,2])
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(xcord1, ycord1, s = 20, c = 'red', marker = 's',alpha=.5)
    ax.scatter(xcord2, ycord2, s = 20, c = 'green',alpha=.5)
    plt.title('DataSet')
    plt.xlabel('x'); plt.ylabel('y')
    plt.show()
  ```
  * 伪代码
    ```python
    def plotDataSet():
      特征向量矩阵, 标签向量列表 = loadDataSet()
      特征向量矩阵 = np.array(特征向量矩阵)
      n = 特征向量矩阵行数(训练集实例个数)
      分类1x轴 = []; 分类1y轴 = []
      分类2x轴 = []; 分类2y轴 = []
      for 每一个特征向量 in range(n):
        if 标签向量列表[此特征向量] == 1:
          分类1x轴.添加(此向量第一个特征); 分类1y轴.添加(此向量第二个特征)
        else:
          分类2x轴.添加(此向量第一个特征); 分类2y轴.添加(此向量第二个特征)
      根据上述四个列表绘制图像
    ```
* SIGMOD函数以及梯度上升算法(数据集较小,缺失值较多)
  ```python
  def sigmoid(inX):
    return 1.0 / (1 + np.exp(-inX))
    def gradAscent(dataMatIn, classLabels):
      dataMatrix = np.mat(dataMatIn)
      labelMat = np.mat(classLabels).transpose()
      m, n = np.shape(dataMatrix)
      alpha = 0.001
      maxCycles = 500
      weights = np.ones((n,1))
      for k in range(maxCycles):
          h = sigmoid(dataMatrix * weights)
          error = labelMat - h
          weights = weights + alpha * dataMatrix.transpose() * error
      return weights.getA()
  ```
  * 伪代码
    ```python
    def gradAscent(dataMatIn, classLabels):
      特征变量矩阵 = np.矩阵化(数据集)
      标签向量 = np.矩阵化(标签向量列表).转换成列向量()
      矩阵行数, 矩阵列数 = np.shape(特征变量矩阵)
      学习速率 = .001
      最大次循环 = 500
      权重向量 = np.生成1元素向量((矩阵行数, 1)) # 列向量
      for 第k次循环 in 最大次循环:
        h = SIGMOD函数(特征变量矩阵 * 权重向量) # 结果为列向量
        error = 标签向量 - h
        新权重向量 = 权重向量 + 学习速率 * 特征变量矩阵.转置() * error
      返回 权重向量.转化为列表()
    ```
* 随机梯度上升算法(数据集较大,缺失值较少)
  ```python
  def stocGradAscent1(dataMatrix, classLabels, numIter=150):
    m,n = np.shape(dataMatrix)
    weights = np.ones(n)
    for j in range(numIter):                                           
        dataIndex = list(range(m))
        for i in range(m):           
            alpha = 4/(1.0+j+i)+0.01
            randIndex = int(random.uniform(0,len(dataIndex)))
            h = sigmoid(sum(dataMatrix[randIndex]*weights))
            error = classLabels[randIndex] - h
            weights = weights + alpha * error * dataMatrix[randIndex]
            del(dataIndex[randIndex])
    return weights
  ```
  * 伪代码
    ```python
    def stocGradAscent1(dataMatrix, classLabels, numIter=150):
      矩阵行数, 列数 = np.shape(特征变量矩阵)
      权重向量 = np.生成1元素向量((矩阵列数)) # 行向量
      for 每次迭代 in range(迭代次数):
        数据索引列表 = 列表化(range(0到m))
        for 操作次数 in range(m):
          学习速率 = 4 / (操作次数 + 迭代次数 + 1.0) + 0.01
          随机索引值 =  取整(random.uniform(0, 数据索引列表长度))
          h = SIGMOD函数(求和(特征变量行向量 * 权重行向量))
          error = 标签向量[随机索引值] - h
          新权重向量 = 权重向量 + 学习速率 * error * 特征变量矩阵[随机索引值]
          删除(数据索引列表[随机索引值])
      返回 权重行向量
    ```
* 使用logistic回归算法
  ```python
  def classifyVector(inX, weights):
    prob = sigmoid(sum(inX*weights))
    if prob > 0.5: return 1.0
    else: return 0.0

  def colicTest():
    frTrain = open('horseColicTraining.txt')
    frTest = open('horseColicTest.txt')
    trainingSet = []; trainingLabels = []
    for line in frTrain.readlines():
        currLine = line.strip().split('\t')
        lineArr = []
        for i in range(len(currLine)-1):
            lineArr.append(float(currLine[i]))
        trainingSet.append(lineArr)
        trainingLabels.append(float(currLine[-1]))
    trainWeights = stocGradAscent1(np.array(trainingSet), trainingLabels, 500)
    errorCount = 0; numTestVec = 0.0
    for line in frTest.readlines():
        numTestVec += 1.0
        currLine = line.strip().split('\t')
        lineArr =[]
        for i in range(len(currLine)-1):
            lineArr.append(float(currLine[i]))
        if int(classifyVector(np.array(lineArr), trainWeights))!= int(currLine[-1]):
            errorCount += 1
    errorRate = (float(errorCount)/numTestVec) * 100
    print("测试集错误率为: %.2f%%" % errorRate)
  ```
  * 伪代码
    ```python
    def classifyVector(inX, weights):
      几率 = SIGMOD函数(求和(inX, weights))
      if 几率 > .5:
        返回1
      else:
        返回0
    def colicTest():
      打开训练集文件作为训练集文件对象
      打开测试集文件作为测试集文件对象
      训练集 = []; 训练集标签向量 =[]
      for 每一行 in 训练集文件对象.readlines():
        此行列表 = 这一行.去掉头尾无用字符().使用'\t'分隔()
        每行特征向量列表 = []
        for i in range(此行列表长度 - 1):
          每行特征向量列表.append(此行列表[i])
        训练集.append(此行特征向量列表)
        训练集标签向量列表.append(此行列表[-1])
      权重 = stocGradAscent1(np.array(训练集), 训练标签, 500(迭代次数))
      错误次数 = 0; 测试集实例数 = 0
      for 每一行 in 测试集文件对象.readlines():
        测试集实例数++
        此行列表 = 这一行.去掉头尾无用字符().使用'\t'分隔()
        每行特征向量列表 = []
        for i in range(此行列表长度 - 1):
          每行特征向量列表.append(此行列表[i])
          if int(classifyVector(np.array(此行特征向量列表), 权重)) != 此行列表[-1]:
            错误计数 += 1
      错误率 = 错误计数 / 测试集实例数
    ```
* sklearn+logistic回归
  ```python
  def colicSklearn():
    frTrain = open('horseColicTraining.txt')
    frTest = open('horseColicTest.txt')
    trainingSet = []; trainingLabels = []
    testSet = []; testLabels = []
    for line in frTrain.readlines():
        currLine = line.strip().split('\t')
        lineArr = []
        for i in range(len(currLine)-1):
            lineArr.append(float(currLine[i]))
        trainingSet.append(lineArr)
        trainingLabels.append(float(currLine[-1]))
    for line in frTest.readlines():
        currLine = line.strip().split('\t')
        lineArr =[]
        for i in range(len(currLine)-1):
            lineArr.append(float(currLine[i]))
        testSet.append(lineArr)
        testLabels.append(float(currLine[-1]))
    classifier = LogisticRegression(solver='liblinear',max_iter=10).fit(trainingSet, trainingLabels)
    test_accurcy = classifier.score(testSet, testLabels) * 100
    print('正确率:%f%%' % test_accurcy)
  ```
## 支持向量机
* 读取数据集
  ```python
  def loadDataSet(fileName):
    dataMat = []; labelMat = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr = line.strip().split('\t')
        dataMat.append([float(lineArr[0]), float(lineArr[1])])
        labelMat.append(float(lineArr[2]))
    return dataMat,labelMat
  ```
* 随机选择一个不等于i的j(随机挑选a)
  ```python
  def selectJrand(i, m):
    j = i                                 #选择一个不等于i的j
    while (j == i):
        j = int(random.uniform(0, m))
    return j
  ```
* 修建a(根据上界和下界)
  ```python
  def clipAlpha(aj,H,L):
    if aj > H:
        aj = H
    if L > aj:
        aj = L
    return aj
  ```
* 根据a, y, x计算w(权重)
  ```python
  def get_w(dataMat, labelMat, alphas):
    alphas, dataMat, labelMat = np.array(alphas), np.array(dataMat), np.array(labelMat)
    w = np.dot((np.tile(labelMat.reshape(1, -1).T, (1, 2)) * dataMat).T, alphas)
    return w.tolist()
  ```
* SMO算法
  ```python
  def smoSimple(dataMatIn, classLabels, C, toler, maxIter):
    #转换为numpy的mat存储
    dataMatrix = np.mat(dataMatIn); labelMat = np.mat(classLabels).transpose()
    #初始化b参数，统计dataMatrix的维度
    b = 0; m,n = np.shape(dataMatrix)
    #初始化alpha参数，设为0
    alphas = np.mat(np.zeros((m,1)))
    #初始化迭代次数
    iter_num = 0
    #最多迭代matIter次
    while (iter_num < maxIter):
        alphaPairsChanged = 0
        for i in range(m):
            #步骤1：计算误差Ei
            fXi = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b
            Ei = fXi - float(labelMat[i])
            #优化alpha，更设定一定的容错率。
            if ((labelMat[i]*Ei < -toler) and (alphas[i] < C)) or ((labelMat[i]*Ei > toler) and (alphas[i] > 0)):
                #随机选择另一个与alpha_i成对优化的alpha_j
                j = selectJrand(i,m)
                #步骤1：计算误差Ej
                fXj = float(np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)) + b
                Ej = fXj - float(labelMat[j])
                #保存更新前的aplpha值，使用深拷贝
                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();
                #步骤2：计算上下界L和H
                if (labelMat[i] != labelMat[j]):
                    L = max(0, alphas[j] - alphas[i])
                    H = min(C, C + alphas[j] - alphas[i])
                else:
                    L = max(0, alphas[j] + alphas[i] - C)
                    H = min(C, alphas[j] + alphas[i])
                if L==H: print("L==H"); continue
                #步骤3：计算eta
                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T
                if eta >= 0: print("eta>=0"); continue
                #步骤4：更新alpha_j
                alphas[j] -= labelMat[j]*(Ei - Ej)/eta
                #步骤5：修剪alpha_j
                alphas[j] = clipAlpha(alphas[j],H,L)
                if (abs(alphas[j] - alphaJold) < 0.00001): print("alpha_j变化太小"); continue
                #步骤6：更新alpha_i
                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])
                #步骤7：更新b_1和b_2
                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T
                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T
                #步骤8：根据b_1和b_2更新b
                if (0 < alphas[i]) and (C > alphas[i]): b = b1
                elif (0 < alphas[j]) and (C > alphas[j]): b = b2
                else: b = (b1 + b2)/2.0
                #统计优化次数
                alphaPairsChanged += 1
                #打印统计信息
                print("第%d次迭代 样本:%d, alpha优化次数:%d" % (iter_num,i,alphaPairsChanged))
        #更新迭代次数
        if (alphaPairsChanged == 0): iter_num += 1
        else: iter_num = 0
        print("迭代次数: %d" % iter_num)
    return b,alphas
  ```
* 分类结果可视化
  ```python
  def showClassifer(dataMat, w, b):
    #绘制样本点
    data_plus = []                                  #正样本
    data_minus = []                                 #负样本
    for i in range(len(dataMat)):
        if labelMat[i] > 0:
            data_plus.append(dataMat[i])
        else:
            data_minus.append(dataMat[i])
    data_plus_np = np.array(data_plus)              #转换为numpy矩阵
    data_minus_np = np.array(data_minus)            #转换为numpy矩阵
    plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1], s=30, alpha=0.7)   #正样本散点图
    plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1], s=30, alpha=0.7) #负样本散点图
    #绘制直线
    x1 = max(dataMat)[0]
    x2 = min(dataMat)[0]
    a1, a2 = w
    b = float(b)
    a1 = float(a1[0])
    a2 = float(a2[0])
    y1, y2 = (-b- a1*x1)/a2, (-b - a1*x2)/a2
    plt.plot([x1, x2], [y1, y2])
    #找出支持向量点
    for i, alpha in enumerate(alphas):
        if alpha > 0:
            x, y = dataMat[i]
            plt.scatter([x], [y], s=150, c='none', alpha=0.7, linewidth=1.5, edgecolor='red')
    plt.show()
  ```
## Adaboost算法
* 数据可视化
  ```python
  def loadSimpData():
    datMat = np.matrix([[ 1. ,  2.1],
        [ 1.5,  1.6],
        [ 1.3,  1. ],
        [ 1. ,  1. ],
        [ 2. ,  1. ]])
    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]
    return datMat,classLabels
  def showDataSet(dataMat, labelMat):
      data_plus = []                                  #正样本
      data_minus = []                                 #负样本
      for i in range(len(dataMat)):
          if labelMat[i] > 0:
              data_plus.append(dataMat[i])
          else:
              data_minus.append(dataMat[i])
      data_plus_np = np.array(data_plus)                                             #转换为numpy矩阵
      data_minus_np = np.array(data_minus)                                         #转换为numpy矩阵
      plt.scatter(np.transpose(data_plus_np)[0], np.transpose(data_plus_np)[1])        #正样本散点图
      plt.scatter(np.transpose(data_minus_np)[0], np.transpose(data_minus_np)[1])     #负样本散点图
      plt.show()
  ```
  * 伪代码
    ```python
    def loadSimpData():
      创建numpy矩阵类型的特征矩阵
      创建数组类型的标签向量列表
      返回 特征矩阵, 标签向量列表
    def showDataSet(dataMat, labelMat):
      正样本特征矩阵 = []
      负样本特征矩阵 = []
      for 行数 in range(特征矩阵的行数):
        if 标签向量列表显示此行为正样本:
          正样本特征矩阵.append(特征矩阵这一行)
        else:
          负样本特征矩阵.append(特征矩阵这一行)
      numpy正样本特征矩阵 = np.array(正样本特征矩阵)
      numpy负样本特征矩阵 = np.array(负样本特征矩阵)
      plt.散点图(np.转置(numpy正样本特征矩阵)[0], np.转置(numpy正样本特征矩阵)[1])
      plt.散点图(np.转置(numpy负样本特征矩阵)[0], np.转置(numpy负样本特征矩阵)[1])
    ```
* 单层决策树分类函数
  ```python
  def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):
    retArray = np.ones((np.shape(dataMatrix)[0],1))                #初始化retArray为1
    if threshIneq == 'lt':
        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0         #如果小于阈值,则赋值为-1
    else:
        retArray[dataMatrix[:,dimen] > threshVal] = -1.0         #如果大于阈值,则赋值为-1
    return retArray
  ```
  * 伪代码
    ```python
    def stumpClassify(特征矩阵,特征维度,阈值,标志):
      分类结果列向量 = np.ones((特征矩阵行数,1))
      if 标志 == 对于小于阈值的样本点赋值-1:
        分类结果列向量[特征矩阵中在给定的特征维度的值 <= 阈值] = -1.0
      else:
        分类结果列向量[特征矩阵中在给定的特征维度的值 > 阈值] = -1.0
      返回 分类结果列向量
    ```
* 找到数据集上最佳单层决策树
  ```python
  def buildStump(dataArr,classLabels,D):
    dataMatrix = np.mat(dataArr); labelMat = np.mat(classLabels).T
    m,n = np.shape(dataMatrix)
    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))
    minError = float('inf')                                                        #最小误差初始化为正无穷大
    for i in range(n):                                                            #遍历所有特征
        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max()        #找到特征中最小的值和最大值
        stepSize = (rangeMax - rangeMin) / numSteps                                #计算步长
        for j in range(-1, int(numSteps) + 1):                                     
            for inequal in ['lt', 'gt']:                                          #大于和小于的情况，均遍历。lt:less than，gt:greater than
                threshVal = (rangeMin + float(j) * stepSize)                     #计算阈值
                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)#计算分类结果
                errArr = np.mat(np.ones((m,1)))                                 #初始化误差矩阵
                errArr[predictedVals == labelMat] = 0                             #分类正确的,赋值为0
                weightedError = D.T * errArr                                      #计算误差
                print("split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f" % (i, threshVal, inequal, weightedError))
                if weightedError < minError:                                     #找到误差最小的分类方式
                    minError = weightedError
                    bestClasEst = predictedVals.copy()
                    bestStump['dim'] = i
                    bestStump['thresh'] = threshVal
                    bestStump['ineq'] = inequal
    return bestStump,minError,bestClasEst
  ```
  * 伪代码
    ```python
    def buildStump(特征矩阵, 标签列表, 样本权重):
      特征矩阵 = np.mat(特征矩阵); 标签列表列向量 = np.mat(标签列表).T
      矩阵行数, 矩阵列数 = np.shape(特征矩阵)
      总步数 = 10.0; 最佳决策树信息字典 = {}; 最佳分类结果列向量 =  np.mat(np.zeros((矩阵行数, 1)))
      最小误差 = 正无穷大
      for 特征索引值 in range(矩阵列数):
        此特征最小值 = 特征矩阵[:, 特征索引值].min(); 此特征最大值 = 特征矩阵[:, 特征索引值].max()
        步长 = (此特征最大值 - 此特征最小值) / 总步数
        for 步数 in (-1 -> 总步数):
          for 大小取值 in [对于小于阈值的样本点赋值-1, 对于大于阈值的样本点赋值-1]:
            阈值 = 此特征最小值 + 步数 * 步长
            分类结果列向量 = stumpClassify(特征矩阵, 特征索引值, 阈值, 取值)
            误差列向量 = np.mat(np.ones((矩阵行数, 1)))
            误差列向量[分类结果列向量此行的值 == 标签列表此行的值] = 0
            加权误差值 = 样本权重.T * 误差列向量
            if 加权误差值 < 最小误差值:
              最小误差值 = 加权误差值
              最佳分类结果列向量 = 分类结果列向量
              最佳决策树信息字典['特征索引'] = 特征索引值
              最佳决策树信息字典['阈值'] = 阈值
              最佳决策树信息字典['大小取值'] = 大小取值
      返回 最佳决策树信息字典, 最小误差值, 最佳分类结果列向量
    ```
* Adaboost算法提升分类器性能
  ```python
  def adaBoostTrainDS(dataArr, classLabels, numIt = 40):
    weakClassArr = []
    m = np.shape(dataArr)[0]
    D = np.mat(np.ones((m, 1)) / m)                                            #初始化权重
    aggClassEst = np.mat(np.zeros((m,1)))
    for i in range(numIt):
        bestStump, error, classEst = buildStump(dataArr, classLabels, D)     #构建单层决策树
        print("D:",D.T)
        alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))         #计算弱学习算法权重alpha,使error不等于0,因为分母不能为0
        bestStump['alpha'] = alpha                                          #存储弱学习算法权重
        weakClassArr.append(bestStump)                                      #存储单层决策树
        print("classEst: ", classEst.T)
        expon = np.multiply(-1 * alpha * np.mat(classLabels).T, classEst)     #计算e的指数项
        D = np.multiply(D, np.exp(expon))                                      
        D = D / D.sum()                                                        #根据样本权重公式，更新样本权重
        #计算AdaBoost误差，当误差为0的时候，退出循环
        aggClassEst += alpha * classEst                                 
        print("aggClassEst: ", aggClassEst.T)
        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T, np.ones((m,1)))     #计算误差
        errorRate = aggErrors.sum() / m
        print("total error: ", errorRate)
        if errorRate == 0.0: break                                             #误差为0，退出循环
    return weakClassArr, aggClassEst
  ```
  * 伪代码
    ```python
    def adaBoostTrainDS(特征矩阵, 标签列向量, 迭代次数=40):
      弱学习算法集合 = []
      矩阵行数 = np.shape(特征矩阵)[0]
      样本权重列向量 = np.mat(np.zeros(m,1) / m)
      提升树标签预测向量 = np.mat(np.zeros((m, 1)))
      for 迭代次数 in range(总迭代次数):
        最佳决策树信息字典, 错误率, 分类结果 = buildStump(特征矩阵, 标签向量, 样本权重列向量)
        此决策树alpha值 = float(0.5 * np.log((1.0 - 错误率) / max(错误率, 1e-16)))
        最佳决策树信息字典['alpha值'] = 此决策树alpha值
        弱学习算法集合.append(最佳决策树信息字典)
        -1 * alpha * y * h(x) = np.multiply(-1 * alpha * np.mat(标签列向量).T, 分类结果)
        样本权重列向量 = np.multiply(D, np.exp(-1 * alpha * y * h(x)))
        样本权重列向量 = 样本权重列向量 / 样本权重列向量.sum()
        提升树标签预测向量 += 此决策树alpha值 * 分类结果 # 整个提升树的预测结果 = sum(各个树预测结果 * 对应alpha值)
        提升树预测错误向量 = np.multiply(np.将正负值转化为-1和1(提升树标签预测向量) != np.mat(标签列向量).T, np.ones((m, 1)))
        提升树预测错误率 = 提升树预测错误向量.sum() / m
        if 错误率 == 0:
          break
        return 弱学习算法集合, 提升树标签预测向量
    ```
* 单层决策树分类函数
  ```python
  def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):
    retArray = np.ones((np.shape(dataMatrix)[0],1))                #初始化retArray为1
    if threshIneq == 'lt':
        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0         #如果小于阈值,则赋值为-1
    else:
        retArray[dataMatrix[:,dimen] > threshVal] = -1.0         #如果大于阈值,则赋值为-1
    return retArray
  ```
  * 伪代码
    ```python
    def stumpClassify(测试集数据矩阵,特征维度,阈值,大小取值):
      预测标签列向量 = np.ones((测试集样例数, 1))
      if 大小取值 == 小于阈值赋值为-1: # 如果指定特征维度的值小于阈值,则分类为-1
        预测标签列向量[测试集数据矩阵[所有行, 特征维度的数值] <= 阈值] = -1
      else: # 如果指定特征维度的值大于阈值,则分类为-1
        预测标签列向量[测试集数据矩阵[所有行, 特征维度的数值] > 阈值] = -1
      返回 预测标签列向量
    ```
* Adaboost分类函数
  ```python
  def adaClassify(datToClass,classifierArr):
    dataMatrix = np.mat(datToClass)
    m = np.shape(dataMatrix)[0]
    aggClassEst = np.mat(np.zeros((m,1)))
    for i in range(len(classifierArr)):                                        #遍历所有分类器，进行分类
        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'], classifierArr[i]['thresh'], classifierArr[i]['ineq'])            
        aggClassEst += classifierArr[i]['alpha'] * classEst
        print(aggClassEst)
    return np.sign(aggClassEst)
  ```
  * 伪代码
    ```python
    def adaClassify(测试集数据矩阵,训练好的分类器):
      特征向量矩阵 = np.mat(测试集数据矩阵)
      样例数 = np.shape(特征向量矩阵)[0]
      提升树标签预测向量 = np.mat(np.zeros((样例数, 1)))
      for 弱分类器序数 in 弱分类器总数:
        单弱分类器预测向量 = stumpClassify(特征向量矩阵, 训练好的分类器[分类器序数]['特征索引'], 训练好的分类器[分类器序数]['阈值'], 训练好的分类器[分类器序数]['大小取值'])
        提升树标签预测向量 += 训练好的分类器[分类器序数]['alpha值'] * 单弱分类器预测向量
        返回 np.将正负值分为-1和1(提升树标签预测向量)      
    ```
* sklearn + adaboost
  ```python
  import numpy as np
  from sklearn.ensemble import AdaBoostClassifier
  from sklearn.tree import DecisionTreeClassifier
  def loadDataSet(fileName):
      numFeat = len((open(fileName).readline().split('\t')))
      dataMat = []; labelMat = []
      fr = open(fileName)
      for line in fr.readlines():
          lineArr = []
          curLine = line.strip().split('\t')
          for i in range(numFeat - 1):
              lineArr.append(float(curLine[i]))
          dataMat.append(lineArr)
          labelMat.append(float(curLine[-1]))
      return dataMat, labelMat
  dataArr, classLabels = loadDataSet('horseColicTraining2.txt')
  testArr, testLabelArr = loadDataSet('horseColicTest2.txt')
  bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 2), algorithm = "SAMME", n_estimators = 10)
  bdt.fit(dataArr, classLabels)
  predictions = bdt.predict(dataArr)
  errArr = np.mat(np.ones((len(dataArr), 1)))
  print('训练集的错误率:%.3f%%' % float(errArr[predictions != classLabels].sum() / len(dataArr) * 100))
  predictions = bdt.predict(testArr)
  errArr = np.mat(np.ones((len(testArr), 1)))
  print('测试集的错误率:%.3f%%' % float(errArr[predictions != testLabelArr].sum() / len(testArr) * 100))
  ```
  * 伪代码
    ```python
    def loadDataSet(fileName):
      特征个数 = len(open(文件名).readline().'\t'分割)
      特征矩阵 = []; 标签向量 = []
      文件对象 = open(文件名)
      for 文件的行 in 文件对象.readlines():
        特征列表 = []
        此行列表 = 此行.去掉头尾().'\t'分割
        for 特征索引值 in 0 -> 特征个数-1:
          特征列表.append(float(此行列表[i]))
        特征矩阵.append(特征列表)
        标签向量.append(float(此行列表[-1]))
      返回 特征矩阵, 标签向量
    训练集特征矩阵, 训练集标签向量 = loadDataSet('病马训练集')
    测试集特征矩阵, 测试集标签向量 = loadDataSet('病马测试集')
    提升树 = AdaBoostClassifier(DecisionTreeClassifier(最大深度=2), 权重计算算法]"SAMME", 学习器个数上限=10)
    提升树.fit(训练集特征矩阵, 训练集标签向量)
    预测结果 = 提升树.predict(测试集特征矩阵)
    错误列表 = np.mat(np.ones((测试集样例数, 1)))
    print(float(错误列表[预测结果 != 测试集标签向量].sum() / 测试集样例数 * 100))
    ```
## 线性回归算法
* 加载数据集
  ```python
  def loadDataSet(fileName):
    numFeat = len(open(fileName).readline().split('\t')) - 1
    xArr = []; yArr = []
    fr = open(fileName)
    for line in fr.readlines():
        lineArr =[]
        curLine = line.strip().split('\t')
        for i in range(numFeat):
            lineArr.append(float(curLine[i]))
        xArr.append(lineArr)
        yArr.append(float(curLine[-1]))
    return xArr, yArr
  ```
  * 伪代码
  ```python
  def loadDataSet(fileName):
    加载文件
    读取文件
    将文件内容整合成特征矩阵, 对应值列表
    返回 特征矩阵, 对应值列表
  ```
* 绘制散点图
  ```python
  def plotDataSet():
    xArr, yArr = loadDataSet('ex0.txt')                                    #加载数据集
    n = len(xArr)                                                        #数据个数
    xcord = []; ycord = []                                                #样本点
    for i in range(n):                                                   
        xcord.append(xArr[i][1]); ycord.append(yArr[i])                    #样本点
    fig = plt.figure()
    ax = fig.add_subplot(111)                                            #添加subplot
    ax.scatter(xcord, ycord, s = 20, c = 'blue',alpha = .5)                #绘制样本点
    plt.title('DataSet')                                                #绘制title
    plt.xlabel('X')
    plt.show()
  ```
  * 伪代码
    ```python
    def plotDataSet():
      特征矩阵, 对应值列表 = loadDataSet(文件名称)
      样例数 = len(特征矩阵)
      x轴值列表 = []; y轴值列表 = []
      for 行数 in range(样例数):
        x轴值列表.append(特征矩阵[行数][1])
        y轴值列表.append(特征矩阵[行数][2])
      fig = plt.figure()
      ax = 散点图(x轴值列表, y轴值列表, 点大小=20, .....)
      ....
    ```
* 计算回归系数w
  ```python
  def standRegres(xArr,yArr):
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    xTx = xMat.T * xMat                            #根据文中推导的公示计算回归系数
    if np.linalg.det(xTx) == 0.0:
        print("矩阵为奇异矩阵,不能求逆")
        return
    ws = xTx.I * (xMat.T*yMat)
    return ws
  ```
  * 伪代码
    ```python
    def standRegres(特征矩阵,对应值列表):
      特征矩阵 = np.mat(特征矩阵); 对应值列向量 = np.mat(对应值列表).T
      xTx = 特征矩阵.T * 特征矩阵
      if xTx.行列式的值 == 0:
        搞不定
      else:
        权重列向量 = xTx.求逆 * (特征矩阵.T * 对应值列向量)
      返回 权重列向量
    ```
* 绘制回归曲线和数据点
  ```python
  def plotRegression():
    xArr, yArr = loadDataSet('ex0.txt')                                    #加载数据集
    ws = standRegres(xArr, yArr)                                        #计算回归系数
    xMat = np.mat(xArr)                                                    #创建xMat矩阵
    yMat = np.mat(yArr)                                                    #创建yMat矩阵
    xCopy = xMat.copy()                                                    #深拷贝xMat矩阵
    xCopy.sort(0)                                                        #排序
    yHat = xCopy * ws                                                     #计算对应的y值
    fig = plt.figure()
    ax = fig.add_subplot(111)                                            #添加subplot
    ax.plot(xCopy[:, 1], yHat, c = 'red')                                #绘制回归曲线
    ax.scatter(xMat[:,1].flatten().A[0], yMat.flatten().A[0], s = 20, c = 'blue',alpha = .5)                #绘制样本点
    plt.title('DataSet')                                                #绘制title
    plt.xlabel('X')
    plt.show()
  ```
  * 伪代码
    ```python
    def plotRegression():
      特征矩阵, 对应值列表 = loadDataSet(文件名称)
      权重列向量 = standRegres(特征矩阵, 对应值列表)
      特征矩阵 = np.mat(特征矩阵)
      特征值列向量 = np.mat(对应值列表)
      拷贝特征矩阵 = 特征矩阵.copy()
      拷贝特征矩阵.排序(0)
      预测向量 = 拷贝特征向量 * 权重列向量
      fig = plt.figure()
      ax = fig.add_subplot(111)
      ax.plot(拷贝特征矩阵[:, 1], 预测向量, c=红色)
      ax.散点图(特征矩阵[:, 1].拉伸成一维().转换成array, 特征值列向量.拉伸成一维().转换成array)
      设置图例
    ```
* 比较真实值和预测值之间的相关性
  ```python
  xArr, yArr = loadDataSet('ex0.txt')                                    #加载数据集
  ws = standRegres(xArr, yArr)                                        #计算回归系数
  xMat = np.mat(xArr)                                                    #创建xMat矩阵
  yMat = np.mat(yArr)                                                    #创建yMat矩阵
  yHat = xMat * ws
  print(np.corrcoef(yHat.T, yMat))
  ```
  * 伪代码
    ```python
    特征矩阵, 对应值列表 = loadDataSet(文件名称)
    权重列向量 = standRegres(特征矩阵, 对应值列表)
    特征矩阵 = np.mat(特征矩阵)
    特征值列向量 = np.mat(对应值列表)
    预测向量 = 特征矩阵 * 权重列向量
    print(np.corroef(预测向量.T, 特征值列向量)) # 记住要转置
    ```
* 局部加权线性回归算法
  ```python
  def lwlr(testPoint, xArr, yArr, k = 1.0):
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    m = np.shape(xMat)[0]
    weights = np.mat(np.eye((m)))                                        #创建权重对角矩阵
    for j in range(m):                                                  #遍历数据集计算每个样本的权重
        diffMat = testPoint - xMat[j, :]                                 
        weights[j, j] = np.exp(diffMat * diffMat.T/(-2.0 * k**2))
    xTx = xMat.T * (weights * xMat)                                        
    if np.linalg.det(xTx) == 0.0:
        print("矩阵为奇异矩阵,不能求逆")
        return
    ws = xTx.I * (xMat.T * (weights * yMat))                            #计算回归系数
    return testPoint * ws
  ```
  * 伪代码
    ```python
    def lwlr(测试样本点特征, 特征矩阵, 对应值列表, 高斯核参数 = 1.0):
      特征矩阵 = np.mat(特征矩阵); 特征值列向量 = np.mat(对应值列表).T
      矩阵行数 = np.shape(特征矩阵)[0]
      点权重矩阵 = np.mat(np.eye((矩阵行数)))
      for 行数 in 矩阵行数:
        差值行向量 = 测试样本点特征 - 特征矩阵[行数,:]
        点权重矩阵[行数, 行数] = np.exp(差值行向量 * 差值行向量.T / (-2 * k ^ 2))
      xTx = 特征矩阵.T * (点权重矩阵 * 特征矩阵)
      if xTx矩阵的行列式 = 0:
        搞不定
      权重列向量 = xTx.求逆 * (特征矩阵.T * (权重矩阵 * 特征值列向量))
      返回 测试样本点特征 * 权重列向量 # 每调用一次这个方法,只会产生一个预测值
    ```
* 局部加权线性回归测试
  ```python
  def lwlrTest(testArr, xArr, yArr, k=1.0):  
      m = np.shape(testArr)[0]                                            #计算测试数据集大小
      yHat = np.zeros(m)    
      for i in range(m):                                                    #对每个样本点进行预测
          yHat[i] = lwlr(testArr[i],xArr,yArr,k)
      return yHat
  ```
  * 伪代码
    ```python
    def lwlrTest(测试数据集, 特征矩阵, 对应值列表, 高斯核参数=1.0):
      测试集样例数 = np.shape(测试数据集)[0]
      预测向量 = np.零矩阵(m,1)
      for 样例 in 样例数:
        预测向量[样例] = lwlr(测试数据集[样例], 特征矩阵, 对应值列表, 高斯核参数)
      返回 预测向量
    ```
* 绘制多条局部加权回归曲线
  ```python
  def plotlwlrRegression():
    font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)
    xArr, yArr = loadDataSet('ex0.txt')                                    #加载数据集
    yHat_1 = lwlrTest(xArr, xArr, yArr, 1.0)                            #根据局部加权线性回归计算yHat
    yHat_2 = lwlrTest(xArr, xArr, yArr, 0.01)                            #根据局部加权线性回归计算yHat
    yHat_3 = lwlrTest(xArr, xArr, yArr, 0.003)                            #根据局部加权线性回归计算yHat
    xMat = np.mat(xArr)                                                    #创建xMat矩阵
    yMat = np.mat(yArr)                                                    #创建yMat矩阵
    srtInd = xMat[:, 1].argsort(0)                                        #排序，返回索引值
    xSort = xMat[srtInd][:,0,:]
    fig, axs = plt.subplots(nrows=3, ncols=1,sharex=False, sharey=False, figsize=(10,8))                                        
    axs[0].plot(xSort[:, 1], yHat_1[srtInd], c = 'red')                        #绘制回归曲线
    axs[1].plot(xSort[:, 1], yHat_2[srtInd], c = 'red')                        #绘制回归曲线
    axs[2].plot(xSort[:, 1], yHat_3[srtInd], c = 'red')                        #绘制回归曲线
    axs[0].scatter(xMat[:,1].flatten().A[0], yMat.flatten().A[0], s = 20, c = 'blue', alpha = .5)                #绘制样本点
    axs[1].scatter(xMat[:,1].flatten().A[0], yMat.flatten().A[0], s = 20, c = 'blue', alpha = .5)                #绘制样本点
    axs[2].scatter(xMat[:,1].flatten().A[0], yMat.flatten().A[0], s = 20, c = 'blue', alpha = .5)                #绘制样本点
    #设置标题,x轴label,y轴label
    axs0_title_text = axs[0].set_title(u'局部加权回归曲线,k=1.0',FontProperties=font)
    axs1_title_text = axs[1].set_title(u'局部加权回归曲线,k=0.01',FontProperties=font)
    axs2_title_text = axs[2].set_title(u'局部加权回归曲线,k=0.003',FontProperties=font)
    plt.setp(axs0_title_text, size=8, weight='bold', color='red')  
    plt.setp(axs1_title_text, size=8, weight='bold', color='red')  
    plt.setp(axs2_title_text, size=8, weight='bold', color='red')  
    plt.xlabel('X')
    plt.show()
  ```
  * 伪代码
    ```python
    def plotlwlrRegression():
      字体对象 = FontProperties(字体文件名)
      特征矩阵, 对应值列表 = loadDataSet(文件名)
      预测向量_1 = lwlrTest(特征矩阵, 对应值列表, 1.0)
      预测向量_2 = lwlrTest(特征矩阵, 对应值列表, 0.01)
      预测向量_3 = lwlrTest(特征矩阵, 对应值列表, 0.003)
      特征矩阵 = np.mat(特征矩阵)
      特征值列向量 = np.mat(对应值列表)
      排序索引值 = 特征矩阵[所有行, 第2列].返回排序的索引值(升序)
      排序后的特征矩阵 = 将特征矩阵按照第二列的数值排序
      fig, axs = plt.子图(行数=3, 列数=1, 共享x轴=false, 共享y轴=false, 图像大小设置)
      axs[0].折线图(排序好的特征矩阵[第二列], 预测向量_1[排序索引值])
      axs[1].折线图(排序好的特征矩阵[第二列], 预测向量_2[排序索引值])
      axs[2].折线图(排序好的特征矩阵[第二列], 预测向量_3[排序索引值])
      axs[0].散点图(特征矩阵[第二列].拉伸成一维.转换成array(), 特征值列向量.拉伸成一维.转换成array)
      axs[1].散点图(特征矩阵[第二列].拉伸成一维.转换成array(), 特征值列向量.拉伸成一维.转换成array)
      axs[2].散点图(特征矩阵[第二列].拉伸成一维.转换成array(), 特征值列向量.拉伸成一维.转换成array)
      设置图例
      show()
    ```
## GBDT算法
* 计算当前数据集对应值的总方差
  ```python
  def caclSE(dataSet):
    '''
    计算CART回归树的节点方差Squared Error
    :param dataSet: 数据集，包含对应值列。  np.array，m*(n+1)
    :return: 当前节点（目标列）的方差
    '''
    if dataSet.shape[0] == 0:
        return 0
    return np.var(dataSet[:, -1]) * dataSet.shape[0]
  ```
  * 伪代码
    ```python
    def caclSE(dataSet):
      if 数据集的大小为0:
        返回 方差=0
      else:
        总方差 = np.求均方差(数据集最后一列(就是对应值那一列)) * 总样本数
        返回 总方差
    ```
* 根据给定特征值与阈值划分数据集
  ```python
  def splitDataSet(dataSet, feature, value):
    '''
    根据给定特征值，二分数据集。
    :param dataSet: 同上
    :param feature: 待划分特征。因为是处理回归问题，这里我们假定数据集的特征都是连续型
    :param value: 阀值
    :return: 特征值小于等于阀值或大于阀值的两个子数据集. k*(n+1), (m-k)*(n+1)
    '''
    arr1 = dataSet[np.nonzero(dataSet[:, feature] <= value)[0], :]  # 利用np.nonzero返回目标样本的索引值
    arr2 = dataSet[np.nonzero(dataSet[:, feature] > value)[0], :]
    return arr1, arr2
  ```
  * 伪代码
    ```python
    def splitDataSet(数据集, 特征索引值, 阈值):
      # np.nonzero()返回的是a tuple of np.array,所以后面要接[0]表示第一个np.array
      小于阈值的样本索引列表 = np.返回非0元素的索引(数据集在特征索引值的列元素 <= 阈值)[0]
      划分数据集_1 = 数据集[小于阈值的样本索引列表, :]
      大于阈值的样本索引列表 = np.返回非0元素的索引(数据集在特征索引值的列元素 > 阈值)[0]
      划分数据集_2 = 数据集[大于阈值的样本索引列表, :]
      返回 划分数据集_1, 划分数据集_2
    ```
* 使用CART算法选择最优特征以及阈值
  ```python
  def chooseBestFeature(dataSet):
    '''
    通过比较所有节点的方差和，选出方差和最小的特征与对应的特征值
    :param dataSet: 同上
    :return: 最佳划分点和划分值
    '''
    n = dataSet.shape[1] - 1
    minErr = np.inf
    bestFeature, bestValue = 0, 0
    for feature in range(n):
        values = set(dataSet[:, feature].tolist())
        for value in values:
            arr1, arr2 = splitDataSet(dataSet, feature, value)
            err1 = caclSE(arr1)
            err2 = caclSE(arr2)
            newErr = err1 + err2
            if newErr < minErr:
                minErr = newErr
                bestFeature = feature
                bestValue = value
    return bestFeature, bestValue
  ```
  * 伪代码
    ```python
    def chooseBestFeature(dataSet):
    特征数量 = 数据集列数 - 1 # 最后一列是对应值
    最小方差 = 最大的浮点数
    最优切分特征, 最佳阈值 = 0, 0
    for 特征索引值 in 特征数量:
      特征取值集合 = set(数据集[特征索引值这一列].转换为列表())
      for 特征取值 in 特征取值集合:
        # 使用给定特征的每个出现过的取值去尝试切分
        划分数据集_1, 划分数据集_2 = splitDataSet(数据集, 特征索引值, 特征取值)
        方差_1 = caclSE(划分数据集_1)
        方差_2 = caclSE(划分数据集_2)
        新方差 = 方差_1 + 方差_2
        if 新方差 < 最小方差:
          最小方差 = 新方差
          最优切分特征 = 特征索引值
          最佳阈值 = 特征取值
    返回 最优切分特征, 最佳阈值
    ```
* 计算数据集对应值的均值
  ```python
  def calcLeaf(dataSet):
    '''
    计算当前节点的目标列均值（作为当前节点的预测值）
    预测值的计算具体是要根据损失函数确定的。
    不同的损失函数，对应不同的叶子节点值。
    平方误差损失的节点值是均值。
    :param dataSet: 同上
    :return: 目标列均值
    '''
    return np.mean(dataSet[:, -1])
  ```
  * 伪代码
    ```python
    def calcLeaf(dataSet):
      返回 np.求均值(数据集[最后一列])
    ```
* 创建CART回归树
  ```python
  def createTree(dataSet, max_depth=4):
    '''
    创建CART回归树
    :param dataSet: 同上
    :param max_depth: 设定回归树的最大深度，防止无限生长（过拟合）
    :return: 字典形式的cart回归树模型
    '''
    if len(set(dataSet[:, -1].tolist())) == 1:  # 如果当前节点的值都相同，结束递归
        return calcLeaf(dataSet)
    if max_depth == 1:  # 如果层数超出设定层数，结束递归
        return calcLeaf(dataSet)
    # 创建回归树
    bestFeature, bestValue = chooseBestFeature(dataSet)
    mytree = {}
    mytree['FeatureIndex'] = bestFeature  # 存储分割特征值的索引
    mytree['FeatureValue'] = bestValue  # 存储阀值
    lSet, rSet = splitDataSet(dataSet, bestFeature, bestValue)
    mytree['left'] = createTree(lSet, max_depth - 1)  # 存储左子树的信息
    mytree['right'] = createTree(rSet, max_depth - 1)  # 存储右子树的信息
  ```
  * 伪代码
    ```python
    def createTree(数据集, 最大深度=4):
      # 递归停止条件
      if len(集合化(数据集[最后一列].转换成列表())) == 1:
        返回 calcLeaf(数据集)
      if 最大深度 == 1:
        返回 calcLeaf(数据集)
      最优划分特征, 最佳阈值 = chooseBestFeature(数据集)
      CART回归树 = {}
      CART回归树['特征索引'] = 最优划分特征
      CART回归树['特征阈值'] = 最佳阈值
      左子集, 右子集 = splitDataSet(数据集, 最优划分特征, 最佳阈值)
      # 递归调用
      CART回归树['左子树'] = createTree(左子集, 最大深度-1)
      CART回归树['右子树'] = createTree(右子集, 最大深度-1)
    ```
* 根据CART回归树预测单个样本的值
  ```python
  def predict_byCart(cartTree, testData):
    '''
    根据训练好的cart回归树，预测待测数据的值
    :param cartTree: 训练好的cart回归树
    :param testData: 待测试数据, 1*n
    :return: 预测值
    '''
    if not isinstance(cartTree, dict):  # 不是字典，意味着到了叶子结点，此时返回叶子结点的值即可
        return cartTree
    featureIndex = cartTree['FeatureIndex']  # 获取回归树的第一层特征索引
    featureVal = testData[featureIndex]  # 根据特征索引找到待测数据对应的特征值， 作为下面是进入左子树还是右子树的依据
    if featureVal <= cartTree['FeatureValue']:
        return predict_byCart(cartTree['left'], testData)
    elif featureVal > cartTree['FeatureValue']:
        return predict_byCart(cartTree['right'], testData)
  ```
  * 伪代码
    ```python
    def predict_byCart(CART回归树, 样本):
      if 传递进来的CART回归树不是字典:
        返回CART回归树
      特征索引 = CART回归树['特征索引']
      此特征的值 = 样本[特征索引]
      if 此特征的值 <= CART回归树['特征阈值']:
        返回 predict_byCart(CART回归树['左子树'], 样本)
      elif 此特征的值 > CART回归树['特征阈值']:
        return predict_byCart(CART回归树['右子树'], 样本)
    ```
* 根据CART回归树预测所有样本的值
  ```python
  def predict_all_byCart(cartTree, testData):
    '''
    根据训练好的cart回归树预测所有待测数据的值
    :param cartTree: 同上
    :param testData: 待测试数据，m*n
    :return: 预测值，1*m
    '''
    testData = np.array(testData)
    predictions = np.zeros(testData.shape[0])
    for i in range(testData.shape[0]):
        predictions[i] = predict_byCart(cartTree, testData[i])
    return predictions
  ```
  * 伪代码
    ```python
    def predict_all_byCart(cartTree, testData):
      样本集 = np.array(样本集)
      预测值向量 = np.zeros(样本集的行数)
      for i in range(样本集行数):
        预测值向量[i] = predict_byCart(CART回归树, 样本集[i])
    ```
* 训练GDBT回归树
  ```python
  def GBDTtraining(dataSet, numIt=4):
    '''
    训练GBDT回归树,简化版本，这里没根据Shrinkage思想添加正则化参数step
    :param dataSet: 同上
    :param numIt: 梯度下降轮次，即生成弱学习器的个数
    :return: cart回归树组成的列表
    '''
    fx_pre = np.mean(dataSet[:, -1])  # 记录前m-1个模型的预测值之和(初始值是所有值的均值)
    weakRegArr = []  # 弱学习器的列表
    weakRegArr.append(fx_pre)  # 把初始值添加进最终模型，预测时使用
    targets = dataSet[:, -1].copy()  # 存储训练集的目标值
    for i in range(numIt):
        dataSet[:, -1] = targets - fx_pre  # 平方误差损失的一阶导的负数（负梯度）正好是目标值与预测值的差
        mytree = createTree(dataSet)  # 把原目标列替换为残差后，训练弱学习器
        weakRegArr.append(mytree)
        fx_pre += predict_all_byCart(mytree, dataSet[:, : -1])  # 计算所有模型的预测值之和（针对训练集）
        loss = np.var(targets - fx_pre) * targets.shape[0]  # 计算损失函数
        print('Iter:%d, Loss: %.6f' % (i + 1, loss))
        if loss == 0:  # 损失为0，跳出循环。或者可以设定一个阀值，当小于该阀值的时候，退出循环
            break
    return weakRegArr
  ```
  * 伪代码
    ```python
    def GBDTtraining(dataSet, numIt=4):
      前m-1个模型预测值 = np.mean(数据集[最后一列])
      弱学习器列表 = []
      弱学习器列表.append(前m-1个模型预测值)
      训练集的目标值 = 数据集[最后一列].copy()
      for 迭代次数 in 总迭代次数:
        数据集[最后一列] = 训练集的目标值 - 前m-1个模型的预测值 # 负梯度 = 目标值 - 预测值
        CART回归树 = createTree(数据集)
        弱学习器列表.append(CART回归树)
        前m个模型的预测值 = 前m-1个模型的预测值 + predict_all_byCart(CART回归树, 数据集[第一列 -> 最后一列])
        损失 = np.求均方差(训练集的目标值 - 前m个模型的预测值) * 样本数量
        if 损失 == 0:
          break
      返回 弱学习器列表
    ```
* 使用GDBT进行预测
  ```python
  def predict(GBDTtree, testData):
    '''
    根据训练好的GDBT模型，预测待测数据
    :param GBDTtree: 训练好的GBDT模型
    :param testData: 待测数据m*n, m>=1
    :return: 预测值
    '''
    testData = np.array(testData)
    predict = GBDTtree[0]  # 模型的初始化值f0x
    for cart in GBDTtree[1:]:  # cart树从索引1开始
        predict += predict_all_byCart(cart, testData)  # 累加预测结果
    return predict
  ```
  * 伪代码
    ```python
    def predict(GBDTtree, testData):
      测试集 = np.array(测试集)
      预测值 = 弱学习器列表[0]
      for CART回归树 in 弱学习器列表[1 -> 最后]:
        预测值 += predict_all_byCart(CART回归树, 测试集)
      返回 预测值
    ```
## 岭回归(将不重要的特征权重缩小至接近0)
* 产生岭回归的回归系数
  ```python
  def ridgeRegres(xMat, yMat, lam = 0.2):
    xTx = xMat.T * xMat
    denom = xTx + np.eye(np.shape(xMat)[1]) * lam
    if np.linalg.det(denom) == 0.0:
        print("矩阵为奇异矩阵,不能转置")
        return
    ws = denom.I * (xMat.T * yMat)
    return ws
  ```
  * 伪代码
    ```python
    # 单位矩阵权重增大会减小回归系数的值的绝对值, 控制单位矩阵权重可以简化模型
    def ridgeRegres(特征矩阵, 对应值列表向量, 单位矩阵权重 = 0.2):
      xTx = 特征矩阵.T * 特征矩阵
      (xTx + 单位矩阵权重 * I) = xTx + np.单位矩阵(特征矩阵列数) * 单位矩阵权重
      if np.求行列式(xTx + 单位矩阵权重 * I) == 0:
        搞不定了
      回归系数 = (xTx + 单位矩阵权重 * I) * (特征矩阵.T * 对应值列表向量)
      返回 回归系数
    ```
* 岭回归测试
  ```python
  def ridgeTest(xArr, yArr):
    xMat = np.mat(xArr); yMat = np.mat(yArr).T
    #数据标准化
    yMean = np.mean(yMat, axis = 0)                        #行与行操作，求均值
    yMat = yMat - yMean                                    #数据减去均值
    xMeans = np.mean(xMat, axis = 0)                    #行与行操作，求均值
    xVar = np.var(xMat, axis = 0)                        #行与行操作，求方差
    xMat = (xMat - xMeans) / xVar                        #数据减去均值除以方差实现标准化
    numTestPts = 30                                        #30个不同的lambda测试
    wMat = np.zeros((numTestPts, np.shape(xMat)[1]))    #初始回归系数矩阵
    for i in range(numTestPts):                            #改变lambda计算回归系数
        ws = ridgeRegres(xMat, yMat, np.exp(i - 10))    #lambda以e的指数变化，最初是一个非常小的数，
        wMat[i, :] = ws.T                                 #计算回归系数矩阵
    return wMat
  ```
  * 伪代码
    ```python
    def ridgeTest(特征矩阵, 对应值列表):
      特征矩阵 = np.mat(特征矩阵); 对应值列表向量 = np.mat(对应值列表).T
      # 将数据标准化
      对应值均值 = np.mean(对应值列表向量, axis=行间相加)
      标准化对应值列表向量 = 对应值列表向量 - 对应值均值
      特征矩阵均值行向量 = np.mean(特征矩阵, axis=行间相加)
      特征矩阵方差行向量 = np.方差(特征矩阵, axis=行间求方差)
      标准化特征矩阵 = (特征矩阵 - 特征矩阵均值行向量) / 特征矩阵方差行向量
      可能的lamda取值个数 = 30
      回归系数矩阵 = np.零矩阵((可能的lamda取值个数, 特征矩阵列数))
      for i in 可能的lamda取值个数:
        回归系数列向量 = ridgeRegres(标准化特征矩阵, 标准化对应值列表向量, np.exp(i - 10))
        回归系数矩阵[第i行] = 回归系数列向量.T
      返回 回归系数矩阵
    ```
## 前向逐步线性回归
* 数据标准化
  ```python
  def regularize(xMat, yMat):
    inxMat = xMat.copy()                                                        #数据拷贝
    inyMat = yMat.copy()
    yMean = np.mean(yMat, 0)                                                    #行与行操作，求均值
    inyMat = yMat - yMean                                                        #数据减去均值
    inMeans = np.mean(inxMat, 0)                                                   #行与行操作，求均值
    inVar = np.var(inxMat, 0)                                                     #行与行操作，求方差
    inxMat = (inxMat - inMeans) / inVar                                            #数据减去均值除以方差实现标准化
    return inxMat, inyMat
  ```
  * 伪代码
    ```python
    def regularize(特征矩阵, 对应值列表列向量):
      拷贝_特征矩阵 = 特征矩阵.copy()
      拷贝_对应值列表列向量 = 对应值列表列向量.copy()
      对应值均值 = np.mean(对应值列表列向量, 0)
      拷贝_对应值列表列向量 = 对应值列表列向量 - 对应值均值
      特征矩阵均值行向量 = np.mean(特征矩阵, 0)
      特征矩阵方差行向量 = np.var(特征矩阵, 0)
      拷贝_特征矩阵 = (特征矩阵 - 特征矩阵均值行向量) / 特征矩阵方差行向量
    ```
* 计算平方误差
  ```python
  def rssError(yArr,yHatArr):
    return ((yArr-yHatArr)**2).sum()
  ```
  * 伪代码
    ```python
    def rssError(对应值列表列向量, 预测值列向量):
      返回 ((对应值列表列向量 - 预测值列向量) ** 2).sum()
    ```
* 前向逐步线性回归
  ```python
  def stageWise(xArr, yArr, eps = 0.01, numIt = 100):
    xMat = np.mat(xArr); yMat = np.mat(yArr).T                                         #数据集
    xMat, yMat = regularize(xMat, yMat)                                                #数据标准化
    m, n = np.shape(xMat)
    returnMat = np.zeros((numIt, n))                                                #初始化numIt次迭代的回归系数矩阵
    ws = np.zeros((n, 1))                                                            #初始化回归系数矩阵
    wsTest = ws.copy()
    wsMax = ws.copy()
    for i in range(numIt):                                                            #迭代numIt次
        # print(ws.T)                                                                    #打印当前回归系数矩阵
        lowestError = float('inf');                                                 #正无穷
        for j in range(n):                                                            #遍历每个特征的回归系数
            for sign in [-1, 1]:
                wsTest = ws.copy()
                wsTest[j] += eps * sign                                                #微调回归系数
                yTest = xMat * wsTest                                                #计算预测值
                rssE = rssError(yMat.A, yTest.A)                                    #计算平方误差
                if rssE < lowestError:                                                #如果误差更小，则更新当前的最佳回归系数
                    lowestError = rssE
                    wsMax = wsTest
        ws = wsMax.copy()
        returnMat[i,:] = ws.T                                                         #记录numIt次迭代的回归系数矩阵
    return returnMat
  ```
  * 伪代码
    ```python
    def stageWise(特征矩阵, 对应值列表列向量, 步长 = 0.01, 迭代次数 = 100):
      标准化特征矩阵, 标准化对应值列表 = regularize(特征矩阵, 对应值列表)
      矩阵行数, 列数 = np.shape(特征矩阵)
      回归系数矩阵 = np.zeros((迭代次数, 特征维度数))
      回归系数列向量 = np.zeros((特征维度数, 1))
      测试_回归系数 = 回归系数列向量.copy()
      每轮最佳_回归系数 = 回归系数列向量.copy()
      for i in range(迭代次数):
        最小误差 = 最大浮点数
        for j in range(特征维度数):
          for 正负 in [-1, 1]:
            测试_回归系数 = 回归系数列向量.copy()
            测试_回归系数[j] += 步长 * 正负
            测试_预测值向量 = 标准化特征矩阵 * 测试_回归系数
            总平方误差 = rssError(标准化对应值列表, 测试_预测值向量)
            if 总平方误差 < 最小误差:
              更新 最小误差, 每轮最佳_回归系数
        回归系数列向量 = 每轮最佳_回归系数
        回归系数矩阵[i, :] = 回归系数列向量.T
      返回 回归系数矩阵
    ```
## k-means聚类算法
* 加载数据集
  ```python
  def loadDataSet(fileName):
    dataMat = []
    fr = open(fileName)
    for line in fr.readlines(): #for each line
        curLine = line.strip().split('\t')
        fltLine = list(map(float,curLine)) #这里和书中不同 和上一章一样修改
        dataMat.append(fltLine)
    return dataMat
  ```
  * 伪代码
    ```python
    def loadDataSet(fileName):
      数据集 = []
      文件对象 = open(filename)
      for 行 in fr.readlines():
        当前行列表 = 行.去掉多余字符().'\t'分割()
        浮点_当前行列表 = list(map(转换成浮点数, 当前行列表))
        数据集.append(浮点_当前行列表)
      返回 数据集
    ```
* 计算欧氏距离
  ```python
  def distEclud(vecA,vecB):
    return sqrt(sum(power(vecA - vecB, 2)))  # la.norm(vecA-vecB) 向量AB的欧式距离
  ```
  * 伪代码
    ```python
    def distEclud(vecA,vecB):
      返回 开方(求和((向量A - 向量B) ** 2))
    ```
* 在样本集中随机选取k个样本点作为初始质心
  ```python
  def initCentroids(dataSet, k):  
    numSamples, dim = np.shape(datatSet)   #矩阵的行数、列数
    centroids = zeros((k, dim))         #感觉要不要你都可以
    for i in range(k):  
        index = int(random.uniform(0, numSamples))  #随机产生一个浮点数，然后将其转化为int型
        centroids[i, :] = dataSet[index, :]  
    return centroids
  ```
  * 伪代码
    ```python
    def initCentroids(dataSet, k):
      矩阵行数, 列数 = np.shape(数据集)
      初始中心矩阵 = np.zeros((k, 矩阵列数))
      for i in range(k):
        随机索引值 = int(random.uniform(0, 矩阵行数))
        初始中心矩阵[i, :] = 数据集[随机索引值]
      返回 初始中心矩阵
    ```
* kmeans算法
  ```python
  def kmeans(dataSet, k):  
    numSamples = dataSet.shape[0]  #读取矩阵dataSet的第一维度的长度,即获得有多少个样本数据
    # first column stores which cluster this sample belongs to,  
    # second column stores the error between this sample and its centroid  
    clusterAssment = mat(zeros((numSamples, 2)))  #得到一个N*2的零矩阵
    clusterChanged = True  

    ## step 1: init centroids  
    centroids = initCentroids(dataSet, k)  #在样本集中随机选取k个样本点作为初始质心

    while clusterChanged:  
        clusterChanged = False  
        ## for each sample  
        for i in range(numSamples):  #range
            minDist  = 100000.0  
            minIndex = 0  
            ## for each centroid  
            ## step 2: find the centroid who is closest  
            #计算每个样本点与质点之间的距离，将其归内到距离最小的那一簇
            for j in range(k):  
                distance = euclDistance(centroids[j, :], dataSet[i, :])  
                if distance < minDist:  
                    minDist  = distance  
                    minIndex = j  

            ## step 3: update its cluster
            #k个簇里面与第i个样本距离最小的的标号和距离保存在clusterAssment中
            #若所有的样本不在变化，则退出while循环
            if clusterAssment[i, 0] != minIndex:  
                clusterChanged = True  
                clusterAssment[i, :] = minIndex, minDist**2  #两个**表示的是minDist的平方

        ## step 4: update centroids  
        for j in range(k):
            #clusterAssment[:,0].A==j是找出矩阵clusterAssment中第一列元素中等于j的行的下标，返回的是一个以array的列表，第一个array为等于j的下标
            pointsInCluster = dataSet[nonzero(clusterAssment[:, 0].A == j)[0]] #将dataSet矩阵中相对应的样本提取出来
            centroids[j, :] = mean(pointsInCluster, axis = 0)  #计算标注为j的所有样本的平均值

    print ('Congratulations, cluster complete!')  
    return centroids, clusterAssment  
  ```
  * 伪代码
    ```python
    def kmeans(dataSet, k):
      样本数量 = np.shape(数据集)[0]
      类信息矩阵 = np.mat(np.zeros(样本数量, 2)) #第一列为分类索引值, 第二列为距离的平方
      类改变标记 = True
      样本中心 = initCentroids(数据集, k)
      while 类改变标记 == True:
        类改变标记 = False
        # 计算每个样本点与质心之间的距离,将其归类到距离最小的一类
        for i in range(样本数量):
          最小距离 = 10000
          最小距离类索引值 = 0
          for 类别索引值 in range(类数量):
            距离 = euclDistance(样本中心[第j行], 数据集[第i行])
            if 距离 < 最小距离:
              最小距离 = 距离
              最小距离类索引值 = 类别索引值
          if 类信息矩阵[i, 0] != 最小距离类索引值:
            类改变标记 = True
            类信息矩阵[第i行] = 最小距离类索引值, 最小距离**2
        # 更新质心
        for 类别索引值 in range(类数量):
          从属此类的数据集子集 = 数据集[返回非零元素的索引值(类信息矩阵[:, 0].A == 此类)[0]]
          样本中心[类别索引值, :] = mean(从属此类的数据集子集, 行间相加均值)
      返回 样本中心, 类信息矩阵
    ```
* 二分kmeans算法
  ```python
  def biKmeans(dataSet,k,distMeas=distEclud):
    m=shape(dataSet)[0]
    clusterAssment=mat(zeros((m,2)))
    centroid0 = mean(dataSet, axis=0).tolist()[0]
    centList = [centroid0]  # create a list with one centroid
    for j in range(m):  # calc initial Error for each point
        clusterAssment[j, 1] = distEclud(mat(centroid0), dataSet[j, :]) ** 2
    while (len(centList) < k):
        lowestSSE = inf #init SSE
        for i in range(len(centList)):#for every centroid
            ptsInCurrCluster = dataSet[nonzero(clusterAssment[:, 0].A == i)[0],:]  # get the data points currently in cluster i
            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas)# k=2,kMeans
            sseSplit = sum(splitClustAss[:, 1])  # compare the SSE to the currrent minimum
            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, 0].A != i)[0], 1])
            print("sseSplit, and notSplit: ", sseSplit, sseNotSplit)
            if (sseSplit + sseNotSplit) < lowestSSE: #judge the error
                bestCentToSplit = i
                bestNewCents = centroidMat
                bestClustAss = splitClustAss.copy()
                lowestSSE = sseSplit + sseNotSplit
        #new cluster and split cluster
        bestClustAss[nonzero(bestClustAss[:, 0].A == 1)[0], 0] = len(centList)  # change 1 to 3,4, or whatever
        bestClustAss[nonzero(bestClustAss[:, 0].A == 0)[0], 0] = bestCentToSplit
        print('the bestCentToSplit is: ', bestCentToSplit)
        print('the len of bestClustAss is: ', len(bestClustAss))
        centList[bestCentToSplit] = bestNewCents[0, :].tolist()[0]  # replace a centroid with two best centroids
        centList.append(bestNewCents[1, :].tolist()[0])
        clusterAssment[nonzero(clusterAssment[:, 0].A == bestCentToSplit)[0],:] = bestClustAss  # reassign new clusters, and SSE
    return mat(centList), clusterAssment
  ```
  * 二分kmeans算法
    ```python
    def biKmeans(数据集,聚类个数,距离=欧氏距离):
      样本数量 = np.shape(数据集)[0]
      类信息矩阵 = np.mat(np.zeros(样本数量, 2))
      初始类中心 = np.mean(数据集, 行间相加).tolist()[0] # np.mean返回的是一个一维的矩阵
      类中心列表 = [初始类中心]
      for j in range(样本数量):
        类信息矩阵[j, 1] = distEclud(mat(初始类中心), dataSet[第j行]) ** 2 #类信息矩阵第二列存储平方距离
      while (len(类中心列表) < k): # 切分的类不够
        最小总平方误差 = 最大浮点数
        for i in range(len(类中心列表)):
          此类中的数据集 = 数据集[返回非零元素的索引值(类信息矩阵[第1列].A == i)[0], :]
          二分类中心矩阵, 二分类信息矩阵 = kMeans(此类中的数据集, 2)
          分裂类后的总平方误差 = sum(二分类信息矩阵[第二列])
          分裂前的平方误差 = sum(类信息矩阵[返回非零元素的索引值(类信息矩阵[第一列].A != i)[0], 1])
          if(分裂前的平方误差 + 分裂类后的平方误差) < 最小总平方误差:
            最佳切分类 = i
            最佳新样本中心点 = 二分类中心矩阵
            最佳类信息矩阵 = 二分类信息矩阵
            最小总平方误差 = 分裂前的平方误差 + 分裂类后的平方误差
        # 此时已经得到了最佳切分类,按照此类进行切分
        最佳类信息矩阵[分类为第二类的行索引值, 0] = len(类中心列表) #也就是产生的新类的索引值
        最佳类信息矩阵[分类为第一类的行索引值, 0] = 最佳切分类
        类中心列表[最佳切分类] = 最佳新样本中心点[第一行].tolist()[0]
        类中心列表.append(最佳新样本中心点[第二行].tolist()[0])
        类信息矩阵[分类为最佳切分类的行索引值, :] = 最佳类信息矩阵 ##一一对应并赋值
      返回 mat(类中心列表), 类信息矩阵
    ```
